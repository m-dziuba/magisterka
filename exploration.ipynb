{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from utils.preprocessing import clean, remove_stopwords, lemmatize\n",
    "from itertools import combinations_with_replacement\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from gensim.models import KeyedVectors\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "import optuna\n",
    "\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "\n",
    "tf.get_logger().setLevel('INFO')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset():\n",
    "    res = pd.DataFrame()\n",
    "    possible_functions = {\n",
    "        \"clean\": clean,\n",
    "        \"no_stopwords\": remove_stopwords,\n",
    "        \"lemmas\": lemmatize,\n",
    "    }\n",
    "    possible_datasets = set()\n",
    "    for comb in combinations_with_replacement(possible_functions, 3):\n",
    "        possible_datasets.add(tuple(sorted(tuple(set(comb)))))\n",
    "    for func_comb in possible_datasets:\n",
    "        print(func_comb)\n",
    "        resulting_df = df\n",
    "        dataset_name = \"+\".join(func_comb)\n",
    "        for func in func_comb:\n",
    "            resulting_df = possible_functions[func](resulting_df)\n",
    "        res[dataset_name] = resulting_df[\"text\"]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(models_path=\"./models\"):\n",
    "    models_dir = {}\n",
    "    cwd = Path(models_path)\n",
    "    for path in cwd.iterdir():\n",
    "        if path.is_dir():\n",
    "            for file in path.iterdir():\n",
    "                models_dir[file.name] = file\n",
    "    return models_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calculated_models(models_path=\"./results\"):\n",
    "    models_dir = {}\n",
    "    cwd = Path(models_path)\n",
    "    for path in cwd.iterdir():\n",
    "        if path.is_dir():\n",
    "            models_dir[path.name] = []\n",
    "            for file in path.iterdir():\n",
    "                models_dir[path.name].append(file.name)\n",
    "    return models_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(x, y, test_size = 0.15):\n",
    "    x_train_valid, x_test, y_train_valid, y_test = train_test_split(x, y, test_size=test_size, random_state=42)\n",
    "    return *train_test_split(x_train_valid, y_train_valid, test_size=(1 - test_size) * test_size, random_state=42), x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_layer(voc, shape, model):\n",
    "    word_index = dict(zip(voc, range(len(voc))))\n",
    "    num_tokens = len(voc) + 2\n",
    "    embedding_dim = shape[1]    # dimension of vectors\n",
    "    hits = 0\n",
    "    misses = 0\n",
    "\n",
    "    embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        try:\n",
    "            embedding_vector = model.get_vector(word)\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            hits += 1\n",
    "        except KeyError:\n",
    "            misses += 1\n",
    "\n",
    "    embedding_layer = keras.layers.Embedding(\n",
    "        num_tokens,\n",
    "        embedding_dim,\n",
    "        embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "        trainable=False,\n",
    "        input_shape = [None],\n",
    "        mask_zero = True,\n",
    "    )\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_basic_model(embedding_layer, trail):\n",
    "\n",
    "    lstm_first_layer_size = trail.suggest_int(\"lstm_first_layer_size\", 16, 256)\n",
    "    learning_rate = trail.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    model = keras.models.Sequential([\n",
    "        embedding_layer,\n",
    "        keras.layers.LSTM(lstm_first_layer_size),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        metrics=[\"acc\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_in_series_model(embedding_layer, trail):\n",
    "    lstm_first_layer_size = trail.suggest_int(\"lstm_first_layer_size\", 16,  256)\n",
    "    lstm_second_layer_size = trail.suggest_int(\"lstm_second_layer_size\", 16, 256)\n",
    "    lstm_third_layer_size = trail.suggest_int(\"lstm_third_layer_size\", 16, 256)\n",
    "    learning_rate = trail.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    model = keras.models.Sequential([\n",
    "        embedding_layer,\n",
    "        keras.layers.LSTM(lstm_first_layer_size, return_sequences=True),\n",
    "        keras.layers.LSTM(lstm_second_layer_size, return_sequences=True),\n",
    "        keras.layers.LSTM(lstm_third_layer_size),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        metrics=[\"acc\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_cnn_lstm_model(embedding_layer, trail):\n",
    "    lstm_first_layer_size = trail.suggest_int(\"lstm_first_layer_size\", 16, 256)\n",
    "    learning_rate = trail.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    model = keras.models.Sequential([\n",
    "        embedding_layer,\n",
    "        keras.layers.Lambda(lambda x: tf.expand_dims(x, 1)),\n",
    "        keras.layers.Conv2D(100, (2, 2), activation=\"relu\", padding=\"same\"),\n",
    "        keras.layers.MaxPooling2D(pool_size=1),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Reshape((-1, 100)),\n",
    "        keras.layers.LSTM(lstm_first_layer_size),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.summary()\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        metrics=[\"acc\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_model(which, embedding_layer, trail):\n",
    "    if which == \"basic\":\n",
    "        return create_basic_model(embedding_layer, trail)\n",
    "    elif which == \"in_series\":\n",
    "        return create_in_series_model(embedding_layer, trail)\n",
    "    elif which == \"cnn_lstm\":\n",
    "        return create_cnn_lstm_model(embedding_layer, trail)\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "def main(which, x, y, word2vec_model, n_trails=5):\n",
    "    shape = word2vec_model.vectors.shape\n",
    "    vectorizer = TextVectorization(max_tokens=shape[0], output_sequence_length=int(x.str.split().str.len().max()))\n",
    "    vectorizer.adapt(x)\n",
    "\n",
    "    # dict mapping words to their indices\n",
    "    voc = vectorizer.get_vocabulary()\n",
    "\n",
    "    # create embedding layer\n",
    "    vectorized_x = vectorizer(np.array([[s] for s in x])).numpy()\n",
    "    embedding_layer = create_embedding_layer(voc, shape, word2vec_model)\n",
    "\n",
    "    #create model\n",
    "\n",
    "    #test train split\n",
    "    x_train, x_valid, y_train, y_valid, x_test, y_test  = split_dataset(vectorized_x, y)\n",
    "\n",
    "    func = lambda trail: objective(trail, which, embedding_layer, x_train, y_train, x_valid, y_valid)\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\",\n",
    "        pruner=optuna.pruners.MedianPruner(),\n",
    "        storage=\"sqlite:///db.sqlite3\"\n",
    "    )\n",
    "    study.optimize(func, n_trials=n_trails)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    best_trail = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", best_trail.value)\n",
    "    return study\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def load_model(models, file_name):\n",
    "    file = models[file_name]\n",
    "    print(file.name)\n",
    "    return KeyedVectors.load_word2vec_format(file, binary=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def objective(trial, which, embedding_layer, x_train, y_train, x_valid, y_valid):\n",
    "    # Clear clutter from previous session graphs.\n",
    "    keras.backend.clear_session()\n",
    "    # Generate our trial model.\n",
    "    model = create_model(which, embedding_layer, trial)\n",
    "    # Fit the model on the training data.\n",
    "    # The KerasPruningCallback checks for pruning condition every epoch.\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[TFKerasPruningCallback(trial, \"val_acc\")],\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=(x_valid, y_valid),\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # Evaluate the model accuracy on the validation set.\n",
    "    score = model.evaluate(x_valid, y_valid, verbose=0)\n",
    "    return score[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/dane treningowe_I etap.csv\")\n",
    "df_2 = pd.read_csv(\"data/dane testowe.csv\")\n",
    "df = pd.concat([df, df_2])\n",
    "label_binarizer = LabelBinarizer()\n",
    "\n",
    "models = get_models()\n",
    "bin_y = label_binarizer.fit_transform(df[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('no_stopwords',)\n",
      "('clean',)\n",
      "('clean', 'lemmas')\n",
      "('lemmas',)\n",
      "('clean', 'lemmas', 'no_stopwords')\n",
      "('lemmas', 'no_stopwords')\n",
      "('clean', 'no_stopwords')\n"
     ]
    }
   ],
   "source": [
    "dataset = generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 255\n",
    "EPOCHS = 100\n",
    "which = \"cnn_lstm\"\n",
    "modelss = {}\n",
    "\n",
    "curr_results = get_calculated_models(f\"./results/{which}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean+lemmas nkjp+wiki-lemmas-all-100-skipg-hs.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:00:45,686]\u001B[0m A new study created in RDB with name: no-name-c219d900-06e7-4233-a0d2-f8ead9956793\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9403, 100)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         940300    \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 100)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      40100     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 155)               158720    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 156       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,139,276\n",
      "Trainable params: 198,976\n",
      "Non-trainable params: 940,300\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 3s 34ms/step - loss: 0.6926 - acc: 0.6059 - val_loss: 0.6918 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6912 - acc: 0.6054 - val_loss: 0.6898 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6891 - acc: 0.6054 - val_loss: 0.6867 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6853 - acc: 0.6054 - val_loss: 0.6807 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6780 - acc: 0.6054 - val_loss: 0.6678 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6643 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6706 - acc: 0.6054 - val_loss: 0.6638 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6700 - acc: 0.6054 - val_loss: 0.6637 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6699 - acc: 0.6054 - val_loss: 0.6630 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6691 - acc: 0.6055 - val_loss: 0.6614 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6678 - acc: 0.6062 - val_loss: 0.6587 - val_acc: 0.6222\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6608 - acc: 0.6097 - val_loss: 0.6344 - val_acc: 0.6448\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6246 - acc: 0.6624 - val_loss: 0.5583 - val_acc: 0.7128\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5546 - acc: 0.7218 - val_loss: 0.5186 - val_acc: 0.7616\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5237 - acc: 0.7434 - val_loss: 0.5056 - val_acc: 0.7664\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5089 - acc: 0.7507 - val_loss: 0.4969 - val_acc: 0.7712\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4996 - acc: 0.7525 - val_loss: 0.4932 - val_acc: 0.7688\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4981 - acc: 0.7539 - val_loss: 0.4854 - val_acc: 0.7771\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.4863 - acc: 0.7633 - val_loss: 0.4827 - val_acc: 0.7855\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4816 - acc: 0.7657 - val_loss: 0.4825 - val_acc: 0.7855\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.4843 - acc: 0.7635 - val_loss: 0.4841 - val_acc: 0.7676\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4751 - acc: 0.7694 - val_loss: 0.4813 - val_acc: 0.7712\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.4763 - acc: 0.7657 - val_loss: 0.4748 - val_acc: 0.7855\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.4705 - acc: 0.7741 - val_loss: 0.4762 - val_acc: 0.7783\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.4666 - acc: 0.7734 - val_loss: 0.4718 - val_acc: 0.7795\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4658 - acc: 0.7758 - val_loss: 0.4736 - val_acc: 0.7819\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4624 - acc: 0.7774 - val_loss: 0.4709 - val_acc: 0.7819\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4594 - acc: 0.7792 - val_loss: 0.4704 - val_acc: 0.7819\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4620 - acc: 0.7793 - val_loss: 0.4726 - val_acc: 0.7843\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4555 - acc: 0.7853 - val_loss: 0.4741 - val_acc: 0.7700\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4574 - acc: 0.7811 - val_loss: 0.4701 - val_acc: 0.7831\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4525 - acc: 0.7851 - val_loss: 0.4673 - val_acc: 0.7795\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4526 - acc: 0.7860 - val_loss: 0.4742 - val_acc: 0.7890\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4523 - acc: 0.7868 - val_loss: 0.4659 - val_acc: 0.7843\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4483 - acc: 0.7875 - val_loss: 0.4663 - val_acc: 0.7890\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4456 - acc: 0.7915 - val_loss: 0.4662 - val_acc: 0.7867\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4424 - acc: 0.7919 - val_loss: 0.4630 - val_acc: 0.7831\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.4405 - acc: 0.7924 - val_loss: 0.4684 - val_acc: 0.7831\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.4408 - acc: 0.7950 - val_loss: 0.4593 - val_acc: 0.7867\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.4396 - acc: 0.7927 - val_loss: 0.4643 - val_acc: 0.7890\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4350 - acc: 0.7936 - val_loss: 0.4651 - val_acc: 0.7855\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.4353 - acc: 0.7947 - val_loss: 0.4633 - val_acc: 0.7747\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4309 - acc: 0.7985 - val_loss: 0.4695 - val_acc: 0.7723\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4357 - acc: 0.7938 - val_loss: 0.4599 - val_acc: 0.7855\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.4291 - acc: 0.8004 - val_loss: 0.4609 - val_acc: 0.7867\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.4285 - acc: 0.7987 - val_loss: 0.4630 - val_acc: 0.7759\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4296 - acc: 0.7995 - val_loss: 0.4595 - val_acc: 0.7843\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.4258 - acc: 0.8013 - val_loss: 0.4602 - val_acc: 0.7831\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.4263 - acc: 0.8030 - val_loss: 0.4589 - val_acc: 0.7950\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.4230 - acc: 0.8046 - val_loss: 0.4631 - val_acc: 0.7890\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4244 - acc: 0.8016 - val_loss: 0.4584 - val_acc: 0.7807\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4191 - acc: 0.8065 - val_loss: 0.4585 - val_acc: 0.7890\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.4190 - acc: 0.8100 - val_loss: 0.4568 - val_acc: 0.7890\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4189 - acc: 0.8062 - val_loss: 0.4619 - val_acc: 0.7771\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.4158 - acc: 0.8086 - val_loss: 0.4570 - val_acc: 0.7855\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.4137 - acc: 0.8119 - val_loss: 0.4597 - val_acc: 0.7795\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4211 - acc: 0.8097 - val_loss: 0.4566 - val_acc: 0.8021\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.4135 - acc: 0.8114 - val_loss: 0.4539 - val_acc: 0.7986\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.4150 - acc: 0.8116 - val_loss: 0.4534 - val_acc: 0.7914\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4121 - acc: 0.8131 - val_loss: 0.4520 - val_acc: 0.7902\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4123 - acc: 0.8156 - val_loss: 0.4522 - val_acc: 0.7855\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4091 - acc: 0.8138 - val_loss: 0.4611 - val_acc: 0.8010\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4061 - acc: 0.8166 - val_loss: 0.4541 - val_acc: 0.7998\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4078 - acc: 0.8152 - val_loss: 0.4588 - val_acc: 0.7986\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4044 - acc: 0.8213 - val_loss: 0.4502 - val_acc: 0.7878\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4021 - acc: 0.8215 - val_loss: 0.4554 - val_acc: 0.7962\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.3997 - acc: 0.8213 - val_loss: 0.4520 - val_acc: 0.8010\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.3988 - acc: 0.8222 - val_loss: 0.4499 - val_acc: 0.8021\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.3990 - acc: 0.8224 - val_loss: 0.4500 - val_acc: 0.7914\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.3966 - acc: 0.8243 - val_loss: 0.4522 - val_acc: 0.8010\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.3954 - acc: 0.8239 - val_loss: 0.4482 - val_acc: 0.7986\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.3927 - acc: 0.8276 - val_loss: 0.4490 - val_acc: 0.7998\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.3953 - acc: 0.8278 - val_loss: 0.4591 - val_acc: 0.8010\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.3947 - acc: 0.8264 - val_loss: 0.4466 - val_acc: 0.8021\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.3897 - acc: 0.8314 - val_loss: 0.4763 - val_acc: 0.8057\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4012 - acc: 0.8189 - val_loss: 0.4421 - val_acc: 0.7998\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.3889 - acc: 0.8318 - val_loss: 0.4465 - val_acc: 0.7998\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.3825 - acc: 0.8368 - val_loss: 0.4496 - val_acc: 0.7998\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.3813 - acc: 0.8355 - val_loss: 0.4490 - val_acc: 0.7998\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.3820 - acc: 0.8351 - val_loss: 0.4462 - val_acc: 0.8021\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.3782 - acc: 0.8365 - val_loss: 0.4580 - val_acc: 0.8045\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.3829 - acc: 0.8341 - val_loss: 0.4425 - val_acc: 0.8010\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.3763 - acc: 0.8400 - val_loss: 0.4464 - val_acc: 0.8010\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.3757 - acc: 0.8382 - val_loss: 0.4622 - val_acc: 0.8057\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.3758 - acc: 0.8393 - val_loss: 0.4482 - val_acc: 0.8021\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.3786 - acc: 0.8372 - val_loss: 0.4430 - val_acc: 0.8021\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.3729 - acc: 0.8433 - val_loss: 0.4508 - val_acc: 0.8057\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.3709 - acc: 0.8421 - val_loss: 0.4449 - val_acc: 0.8045\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.3695 - acc: 0.8452 - val_loss: 0.4483 - val_acc: 0.8033\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.3711 - acc: 0.8414 - val_loss: 0.4470 - val_acc: 0.7986\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.3676 - acc: 0.8457 - val_loss: 0.4554 - val_acc: 0.8117\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.3637 - acc: 0.8478 - val_loss: 0.4533 - val_acc: 0.8057\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.3617 - acc: 0.8499 - val_loss: 0.4506 - val_acc: 0.8033\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.3633 - acc: 0.8494 - val_loss: 0.4592 - val_acc: 0.8081\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.3608 - acc: 0.8494 - val_loss: 0.4490 - val_acc: 0.7998\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.3589 - acc: 0.8504 - val_loss: 0.4615 - val_acc: 0.8117\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.3554 - acc: 0.8548 - val_loss: 0.4629 - val_acc: 0.8129\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.3534 - acc: 0.8552 - val_loss: 0.4583 - val_acc: 0.8069\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.3539 - acc: 0.8534 - val_loss: 0.4596 - val_acc: 0.8033\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.3524 - acc: 0.8550 - val_loss: 0.4574 - val_acc: 0.8033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:01:23,017]\u001B[0m Trial 0 finished with value: 0.8033373355865479 and parameters: {'lstm_first_layer_size': 155, 'learning_rate': 2.8926732608097648e-05}. Best is trial 0 with value: 0.8033373355865479.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         940300    \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 100)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      40100     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 26)                13208     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 993,635\n",
      "Trainable params: 53,335\n",
      "Non-trainable params: 940,300\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 27ms/step - loss: 0.6929 - acc: 0.6055 - val_loss: 0.6925 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6923 - acc: 0.6054 - val_loss: 0.6919 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6917 - acc: 0.6054 - val_loss: 0.6912 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6911 - acc: 0.6054 - val_loss: 0.6904 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6904 - acc: 0.6054 - val_loss: 0.6896 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6897 - acc: 0.6054 - val_loss: 0.6888 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6889 - acc: 0.6054 - val_loss: 0.6879 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6881 - acc: 0.6054 - val_loss: 0.6869 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6873 - acc: 0.6054 - val_loss: 0.6859 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6864 - acc: 0.6054 - val_loss: 0.6849 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6854 - acc: 0.6054 - val_loss: 0.6837 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6844 - acc: 0.6054 - val_loss: 0.6824 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6832 - acc: 0.6054 - val_loss: 0.6811 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6821 - acc: 0.6054 - val_loss: 0.6797 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6809 - acc: 0.6054 - val_loss: 0.6782 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6796 - acc: 0.6054 - val_loss: 0.6767 - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6783 - acc: 0.6054 - val_loss: 0.6753 - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6771 - acc: 0.6054 - val_loss: 0.6737 - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6759 - acc: 0.6054 - val_loss: 0.6721 - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6747 - acc: 0.6054 - val_loss: 0.6707 - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6737 - acc: 0.6054 - val_loss: 0.6694 - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6728 - acc: 0.6054 - val_loss: 0.6682 - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6721 - acc: 0.6054 - val_loss: 0.6672 - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6666 - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:01:51,359]\u001B[0m Trial 1 finished with value: 0.6185935735702515 and parameters: {'lstm_first_layer_size': 26, 'learning_rate': 1.61019779371001e-05}. Best is trial 0 with value: 0.8033373355865479.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         940300    \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 100)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      40100     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 62)                40424     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,020,887\n",
      "Trainable params: 80,587\n",
      "Non-trainable params: 940,300\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 28ms/step - loss: 0.6815 - acc: 0.6059 - val_loss: 0.6672 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6718 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6668 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6647 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6668 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6672 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6717 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6661 - val_acc: 0.6186\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6698 - acc: 0.6094 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:02:21,302]\u001B[0m Trial 2 finished with value: 0.6185935735702515 and parameters: {'lstm_first_layer_size': 62, 'learning_rate': 0.0005607025005751149}. Best is trial 0 with value: 0.8033373355865479.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         940300    \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 100)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      40100     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 194)               228920    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,209,515\n",
      "Trainable params: 269,215\n",
      "Non-trainable params: 940,300\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 30ms/step - loss: 0.6955 - acc: 0.6054 - val_loss: 0.6776 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6732 - acc: 0.6054 - val_loss: 0.6659 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6661 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6665 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6707 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:03:01,653]\u001B[0m Trial 3 finished with value: 0.6185935735702515 and parameters: {'lstm_first_layer_size': 194, 'learning_rate': 0.0021398027096919013}. Best is trial 0 with value: 0.8033373355865479.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         940300    \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 100)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      40100     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 123)               110208    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 124       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,090,732\n",
      "Trainable params: 150,432\n",
      "Non-trainable params: 940,300\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 27ms/step - loss: 0.7002 - acc: 0.5480 - val_loss: 0.6912 - val_acc: 0.6174\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6944 - acc: 0.5723 - val_loss: 0.6795 - val_acc: 0.5793\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6852 - acc: 0.5862 - val_loss: 0.6880 - val_acc: 0.5554\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6710 - acc: 0.6047 - val_loss: 0.6551 - val_acc: 0.6198\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6660 - acc: 0.6066 - val_loss: 0.6582 - val_acc: 0.6222\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6631 - acc: 0.6102 - val_loss: 0.6552 - val_acc: 0.6269\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6655 - acc: 0.6080 - val_loss: 0.6646 - val_acc: 0.6162\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6799 - acc: 0.5822 - val_loss: 0.6639 - val_acc: 0.6210\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6644 - acc: 0.6089 - val_loss: 0.6579 - val_acc: 0.6305\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6662 - acc: 0.6052 - val_loss: 0.6469 - val_acc: 0.6257\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6671 - acc: 0.6085 - val_loss: 0.6636 - val_acc: 0.6138\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6612 - acc: 0.6083 - val_loss: 0.6461 - val_acc: 0.6305\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6566 - acc: 0.6186 - val_loss: 0.6635 - val_acc: 0.6067\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6615 - acc: 0.6130 - val_loss: 0.6463 - val_acc: 0.6234\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6536 - acc: 0.6226 - val_loss: 0.6412 - val_acc: 0.6293\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6560 - acc: 0.6181 - val_loss: 0.6411 - val_acc: 0.6293\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6584 - acc: 0.6137 - val_loss: 0.6434 - val_acc: 0.6305\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6589 - acc: 0.6132 - val_loss: 0.6494 - val_acc: 0.6317\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6537 - acc: 0.6179 - val_loss: 0.6912 - val_acc: 0.5518\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6619 - acc: 0.6148 - val_loss: 0.6549 - val_acc: 0.6234\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6655 - acc: 0.6143 - val_loss: 0.6428 - val_acc: 0.6484\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6666 - acc: 0.6083 - val_loss: 0.6391 - val_acc: 0.6389\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6489 - acc: 0.6313 - val_loss: 0.6401 - val_acc: 0.6341\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6589 - acc: 0.6118 - val_loss: 0.6409 - val_acc: 0.6424\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6488 - acc: 0.6303 - val_loss: 0.6376 - val_acc: 0.6281\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6448 - acc: 0.6279 - val_loss: 0.6408 - val_acc: 0.6424\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6440 - acc: 0.6322 - val_loss: 0.6392 - val_acc: 0.6257\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6428 - acc: 0.6317 - val_loss: 0.6425 - val_acc: 0.6222\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6432 - acc: 0.6303 - val_loss: 0.6381 - val_acc: 0.6424\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6521 - acc: 0.6284 - val_loss: 0.6514 - val_acc: 0.6174\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6450 - acc: 0.6261 - val_loss: 0.6455 - val_acc: 0.6412\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6422 - acc: 0.6303 - val_loss: 0.6429 - val_acc: 0.6186\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6441 - acc: 0.6299 - val_loss: 0.6802 - val_acc: 0.5662\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6456 - acc: 0.6294 - val_loss: 0.6354 - val_acc: 0.6389\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6394 - acc: 0.6362 - val_loss: 0.6350 - val_acc: 0.6341\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6412 - acc: 0.6343 - val_loss: 0.6354 - val_acc: 0.6377\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6339 - acc: 0.6376 - val_loss: 0.6966 - val_acc: 0.6198\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6621 - acc: 0.6202 - val_loss: 0.6480 - val_acc: 0.6198\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6310 - acc: 0.6451 - val_loss: 0.6554 - val_acc: 0.6222\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6360 - acc: 0.6413 - val_loss: 0.6551 - val_acc: 0.6103\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6316 - acc: 0.6456 - val_loss: 0.6574 - val_acc: 0.6257\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6355 - acc: 0.6381 - val_loss: 0.6385 - val_acc: 0.6436\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6251 - acc: 0.6444 - val_loss: 0.6363 - val_acc: 0.6472\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6237 - acc: 0.6503 - val_loss: 0.6436 - val_acc: 0.6317\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6324 - acc: 0.6448 - val_loss: 0.7241 - val_acc: 0.5375\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6561 - acc: 0.6218 - val_loss: 0.6596 - val_acc: 0.6234\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6308 - acc: 0.6498 - val_loss: 0.6371 - val_acc: 0.6412\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6208 - acc: 0.6496 - val_loss: 0.6384 - val_acc: 0.6400\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6200 - acc: 0.6582 - val_loss: 0.6400 - val_acc: 0.6436\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6166 - acc: 0.6582 - val_loss: 0.6425 - val_acc: 0.6389\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6136 - acc: 0.6627 - val_loss: 0.6548 - val_acc: 0.6103\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6295 - acc: 0.6463 - val_loss: 0.6518 - val_acc: 0.6305\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6147 - acc: 0.6648 - val_loss: 0.6611 - val_acc: 0.6043\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6169 - acc: 0.6601 - val_loss: 0.6493 - val_acc: 0.6293\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6129 - acc: 0.6631 - val_loss: 0.6517 - val_acc: 0.6400\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6264 - acc: 0.6444 - val_loss: 0.6507 - val_acc: 0.6281\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6313 - acc: 0.6381 - val_loss: 0.6463 - val_acc: 0.6353\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6303 - acc: 0.6353 - val_loss: 0.6453 - val_acc: 0.6198\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6153 - acc: 0.6549 - val_loss: 0.6584 - val_acc: 0.6281\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6126 - acc: 0.6526 - val_loss: 0.6586 - val_acc: 0.6174\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6276 - acc: 0.6469 - val_loss: 0.7509 - val_acc: 0.6234\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6649 - acc: 0.6259 - val_loss: 0.7477 - val_acc: 0.5423\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6288 - acc: 0.6437 - val_loss: 0.6493 - val_acc: 0.6436\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6047 - acc: 0.6664 - val_loss: 0.6499 - val_acc: 0.6412\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5990 - acc: 0.6706 - val_loss: 0.6526 - val_acc: 0.6269\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6058 - acc: 0.6655 - val_loss: 0.6532 - val_acc: 0.6281\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6155 - acc: 0.6516 - val_loss: 0.6522 - val_acc: 0.6424\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6061 - acc: 0.6662 - val_loss: 0.6775 - val_acc: 0.5948\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5938 - acc: 0.6782 - val_loss: 0.6502 - val_acc: 0.6341\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6051 - acc: 0.6679 - val_loss: 0.6520 - val_acc: 0.6198\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5946 - acc: 0.6775 - val_loss: 0.6504 - val_acc: 0.6365\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5875 - acc: 0.6903 - val_loss: 0.6849 - val_acc: 0.5900\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5850 - acc: 0.6868 - val_loss: 0.6563 - val_acc: 0.6305\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5781 - acc: 0.6932 - val_loss: 0.6590 - val_acc: 0.6067\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.5767 - acc: 0.6901 - val_loss: 0.6536 - val_acc: 0.6234\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5792 - acc: 0.6897 - val_loss: 0.6424 - val_acc: 0.6400\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5783 - acc: 0.6917 - val_loss: 0.6619 - val_acc: 0.6114\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5675 - acc: 0.7018 - val_loss: 0.6789 - val_acc: 0.5936\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5725 - acc: 0.6958 - val_loss: 0.6482 - val_acc: 0.6198\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5673 - acc: 0.7026 - val_loss: 0.6610 - val_acc: 0.6436\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5638 - acc: 0.7061 - val_loss: 0.6617 - val_acc: 0.6162\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5659 - acc: 0.7028 - val_loss: 0.6504 - val_acc: 0.6353\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5644 - acc: 0.7075 - val_loss: 0.6761 - val_acc: 0.6079\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5624 - acc: 0.7084 - val_loss: 0.6483 - val_acc: 0.6317\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5515 - acc: 0.7147 - val_loss: 0.6567 - val_acc: 0.6257\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5471 - acc: 0.7229 - val_loss: 0.6783 - val_acc: 0.6412\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5461 - acc: 0.7239 - val_loss: 0.7127 - val_acc: 0.6520\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.5685 - acc: 0.7045 - val_loss: 0.6548 - val_acc: 0.6305\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.5558 - acc: 0.7113 - val_loss: 0.6585 - val_acc: 0.6424\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.5374 - acc: 0.7293 - val_loss: 0.6576 - val_acc: 0.6377\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.5347 - acc: 0.7366 - val_loss: 0.6614 - val_acc: 0.6353\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.5442 - acc: 0.7246 - val_loss: 0.6827 - val_acc: 0.6424\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.5513 - acc: 0.7176 - val_loss: 0.6721 - val_acc: 0.6603\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.5370 - acc: 0.7291 - val_loss: 0.6610 - val_acc: 0.6341\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5299 - acc: 0.7366 - val_loss: 0.6772 - val_acc: 0.6400\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5316 - acc: 0.7345 - val_loss: 0.6642 - val_acc: 0.6377\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5297 - acc: 0.7342 - val_loss: 0.6650 - val_acc: 0.6222\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5248 - acc: 0.7380 - val_loss: 0.6592 - val_acc: 0.6424\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5329 - acc: 0.7349 - val_loss: 0.6666 - val_acc: 0.6436\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5186 - acc: 0.7410 - val_loss: 0.6635 - val_acc: 0.6555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:03:39,540]\u001B[0m Trial 4 finished with value: 0.6555423140525818 and parameters: {'lstm_first_layer_size': 123, 'learning_rate': 0.08720889214097857}. Best is trial 0 with value: 0.8033373355865479.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value:  0.8033373355865479\n",
      "lemmas nkjp+wiki-lemmas-all-100-skipg-hs.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:03:40,104]\u001B[0m A new study created in RDB with name: no-name-f8cb6550-0b1d-4e88-bf9b-50329e575d87\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9058, 100)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         905800    \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 100)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      40100     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 115)               99360     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 116       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,045,376\n",
      "Trainable params: 139,576\n",
      "Non-trainable params: 905,800\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 27ms/step - loss: 0.6981 - acc: 0.6029 - val_loss: 0.6806 - val_acc: 0.5125\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6747 - acc: 0.5937 - val_loss: 0.6684 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6774 - acc: 0.5975 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6799 - acc: 0.5914 - val_loss: 0.6671 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6803 - acc: 0.5902 - val_loss: 0.6988 - val_acc: 0.5113\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6808 - acc: 0.6012 - val_loss: 0.6725 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6815 - acc: 0.5879 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6746 - acc: 0.6054 - val_loss: 0.6674 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6721 - acc: 0.6054 - val_loss: 0.6697 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6809 - acc: 0.5918 - val_loss: 0.6699 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6757 - acc: 0.5958 - val_loss: 0.6664 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6735 - acc: 0.6054 - val_loss: 0.6662 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6744 - acc: 0.6054 - val_loss: 0.6686 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6738 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6772 - acc: 0.5932 - val_loss: 0.6684 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6747 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6763 - acc: 0.5878 - val_loss: 0.6826 - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6984 - acc: 0.5653 - val_loss: 0.6929 - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6845 - acc: 0.5810 - val_loss: 0.6720 - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6766 - acc: 0.5980 - val_loss: 0.6661 - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6729 - acc: 0.6054 - val_loss: 0.6778 - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6805 - acc: 0.5996 - val_loss: 0.6720 - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6849 - acc: 0.5892 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6722 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6724 - acc: 0.6054 - val_loss: 0.6661 - val_acc: 0.6186\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6769 - acc: 0.6054 - val_loss: 0.6703 - val_acc: 0.6186\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6762 - acc: 0.5956 - val_loss: 0.6671 - val_acc: 0.6186\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6743 - acc: 0.6054 - val_loss: 0.6840 - val_acc: 0.6186\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6836 - acc: 0.5928 - val_loss: 0.6685 - val_acc: 0.6186\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6756 - acc: 0.6054 - val_loss: 0.6673 - val_acc: 0.6186\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6739 - acc: 0.6054 - val_loss: 0.6700 - val_acc: 0.6186\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6735 - acc: 0.6054 - val_loss: 0.6670 - val_acc: 0.6186\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6752 - acc: 0.6054 - val_loss: 0.6684 - val_acc: 0.6186\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6778 - acc: 0.6054 - val_loss: 0.6754 - val_acc: 0.6186\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6736 - acc: 0.6054 - val_loss: 0.6697 - val_acc: 0.6186\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6735 - acc: 0.6054 - val_loss: 0.6646 - val_acc: 0.6186\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6753 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6742 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6738 - acc: 0.6054 - val_loss: 0.6676 - val_acc: 0.6186\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6737 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6646 - val_acc: 0.6186\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6727 - acc: 0.6054 - val_loss: 0.6646 - val_acc: 0.6186\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6760 - acc: 0.6054 - val_loss: 0.6710 - val_acc: 0.6186\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6790 - acc: 0.6054 - val_loss: 0.6627 - val_acc: 0.6186\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6729 - acc: 0.6054 - val_loss: 0.6641 - val_acc: 0.6186\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6721 - acc: 0.6054 - val_loss: 0.6672 - val_acc: 0.6186\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6727 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6728 - acc: 0.6054 - val_loss: 0.6677 - val_acc: 0.6186\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6786 - acc: 0.6054 - val_loss: 0.6668 - val_acc: 0.6186\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6757 - acc: 0.6007 - val_loss: 0.6629 - val_acc: 0.6186\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6727 - acc: 0.5956 - val_loss: 0.6685 - val_acc: 0.6186\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6657 - acc: 0.6047 - val_loss: 0.6634 - val_acc: 0.6222\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6521 - acc: 0.6076 - val_loss: 0.6476 - val_acc: 0.6305\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6404 - acc: 0.6409 - val_loss: 0.6391 - val_acc: 0.6436\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6399 - acc: 0.6463 - val_loss: 0.6474 - val_acc: 0.6400\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6464 - acc: 0.6430 - val_loss: 0.6695 - val_acc: 0.6186\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6261 - acc: 0.6516 - val_loss: 0.6146 - val_acc: 0.6687\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6045 - acc: 0.6838 - val_loss: 0.6125 - val_acc: 0.6663\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5927 - acc: 0.6885 - val_loss: 0.6047 - val_acc: 0.6734\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5924 - acc: 0.6915 - val_loss: 0.6064 - val_acc: 0.6818\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5900 - acc: 0.6876 - val_loss: 0.5893 - val_acc: 0.6806\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5735 - acc: 0.7094 - val_loss: 0.5961 - val_acc: 0.6818\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.5615 - acc: 0.7159 - val_loss: 0.5850 - val_acc: 0.6818\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5574 - acc: 0.7176 - val_loss: 0.5880 - val_acc: 0.7032\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5467 - acc: 0.7274 - val_loss: 0.5800 - val_acc: 0.6937\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5552 - acc: 0.7225 - val_loss: 0.5941 - val_acc: 0.6830\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5491 - acc: 0.7229 - val_loss: 0.5797 - val_acc: 0.6889\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5418 - acc: 0.7237 - val_loss: 0.5744 - val_acc: 0.6973\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5377 - acc: 0.7302 - val_loss: 0.5617 - val_acc: 0.6973\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5270 - acc: 0.7344 - val_loss: 0.5649 - val_acc: 0.6925\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5292 - acc: 0.7331 - val_loss: 0.5764 - val_acc: 0.6996\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5227 - acc: 0.7363 - val_loss: 0.5487 - val_acc: 0.7092\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5202 - acc: 0.7364 - val_loss: 0.6021 - val_acc: 0.6925\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5178 - acc: 0.7443 - val_loss: 0.5400 - val_acc: 0.7223\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5124 - acc: 0.7415 - val_loss: 0.5564 - val_acc: 0.7056\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5135 - acc: 0.7415 - val_loss: 0.5350 - val_acc: 0.7294\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5056 - acc: 0.7507 - val_loss: 0.5332 - val_acc: 0.7294\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.5022 - acc: 0.7589 - val_loss: 0.5260 - val_acc: 0.7282\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4932 - acc: 0.7622 - val_loss: 0.5301 - val_acc: 0.7294\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4906 - acc: 0.7547 - val_loss: 0.5240 - val_acc: 0.7366\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.4881 - acc: 0.7633 - val_loss: 0.5321 - val_acc: 0.7259\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4959 - acc: 0.7567 - val_loss: 0.5398 - val_acc: 0.7461\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4881 - acc: 0.7628 - val_loss: 0.5431 - val_acc: 0.7414\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4784 - acc: 0.7678 - val_loss: 0.5321 - val_acc: 0.7390\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4812 - acc: 0.7643 - val_loss: 0.5418 - val_acc: 0.7426\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4778 - acc: 0.7678 - val_loss: 0.5336 - val_acc: 0.7354\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4775 - acc: 0.7697 - val_loss: 0.5257 - val_acc: 0.7271\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4702 - acc: 0.7748 - val_loss: 0.5213 - val_acc: 0.7461\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4775 - acc: 0.7671 - val_loss: 0.5316 - val_acc: 0.7330\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4758 - acc: 0.7737 - val_loss: 0.5269 - val_acc: 0.7485\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4707 - acc: 0.7765 - val_loss: 0.5275 - val_acc: 0.7330\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4746 - acc: 0.7703 - val_loss: 0.5160 - val_acc: 0.7449\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4690 - acc: 0.7802 - val_loss: 0.5333 - val_acc: 0.7318\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4677 - acc: 0.7758 - val_loss: 0.5285 - val_acc: 0.7533\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4602 - acc: 0.7781 - val_loss: 0.5147 - val_acc: 0.7497\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4646 - acc: 0.7804 - val_loss: 0.5129 - val_acc: 0.7426\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4652 - acc: 0.7725 - val_loss: 0.5126 - val_acc: 0.7509\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4716 - acc: 0.7741 - val_loss: 0.5077 - val_acc: 0.7521\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4831 - acc: 0.7647 - val_loss: 0.5680 - val_acc: 0.7032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:04:19,068]\u001B[0m Trial 0 finished with value: 0.7032181024551392 and parameters: {'lstm_first_layer_size': 115, 'learning_rate': 0.05723606409949325}. Best is trial 0 with value: 0.7032181024551392.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         905800    \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 100)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      40100     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 24)                12000     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 25        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 957,925\n",
      "Trainable params: 52,125\n",
      "Non-trainable params: 905,800\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 3s 30ms/step - loss: 0.6919 - acc: 0.6054 - val_loss: 0.6900 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6887 - acc: 0.6054 - val_loss: 0.6856 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6844 - acc: 0.6054 - val_loss: 0.6801 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6792 - acc: 0.6054 - val_loss: 0.6736 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6739 - acc: 0.6054 - val_loss: 0.6672 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6707 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6707 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6706 - acc: 0.6054 - val_loss: 0.6647 - val_acc: 0.6186\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6707 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6707 - acc: 0.6054 - val_loss: 0.6646 - val_acc: 0.6186\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6706 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6707 - acc: 0.6054 - val_loss: 0.6645 - val_acc: 0.6186\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6706 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6705 - acc: 0.6054 - val_loss: 0.6645 - val_acc: 0.6186\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6701 - acc: 0.6054 - val_loss: 0.6633 - val_acc: 0.6186\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6686 - acc: 0.6054 - val_loss: 0.6577 - val_acc: 0.6186\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6354 - acc: 0.6054 - val_loss: 0.5954 - val_acc: 0.6186\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6175 - acc: 0.6055 - val_loss: 0.5953 - val_acc: 0.6198\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6078 - acc: 0.6052 - val_loss: 0.5903 - val_acc: 0.6210\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6143 - acc: 0.5630 - val_loss: 0.6288 - val_acc: 0.5185\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6369 - acc: 0.5154 - val_loss: 0.6306 - val_acc: 0.5101\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6353 - acc: 0.5820 - val_loss: 0.6274 - val_acc: 0.6222\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6317 - acc: 0.6059 - val_loss: 0.6217 - val_acc: 0.6186\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6268 - acc: 0.6055 - val_loss: 0.6168 - val_acc: 0.6186\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6244 - acc: 0.6054 - val_loss: 0.6156 - val_acc: 0.6186\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6218 - acc: 0.6054 - val_loss: 0.6085 - val_acc: 0.6186\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6072 - acc: 0.6054 - val_loss: 0.5972 - val_acc: 0.6186\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.6203 - acc: 0.6054 - val_loss: 0.6247 - val_acc: 0.6186\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6297 - acc: 0.6054 - val_loss: 0.6262 - val_acc: 0.6186\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6206 - acc: 0.6054 - val_loss: 0.5829 - val_acc: 0.6186\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6203 - acc: 0.6054 - val_loss: 0.6010 - val_acc: 0.6186\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6321 - acc: 0.6055 - val_loss: 0.6434 - val_acc: 0.6186\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6681 - acc: 0.6054 - val_loss: 0.6316 - val_acc: 0.6186\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6436 - acc: 0.6055 - val_loss: 0.6147 - val_acc: 0.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:04:50,408]\u001B[0m Trial 1 finished with value: 0.6185935735702515 and parameters: {'lstm_first_layer_size': 24, 'learning_rate': 9.901590369957455e-05}. Best is trial 0 with value: 0.7032181024551392.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         905800    \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 100)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      40100     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 196)               232848    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 197       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,178,945\n",
      "Trainable params: 273,145\n",
      "Non-trainable params: 905,800\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 3s 34ms/step - loss: 0.6929 - acc: 0.6054 - val_loss: 0.6926 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6924 - acc: 0.6054 - val_loss: 0.6919 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6917 - acc: 0.6054 - val_loss: 0.6911 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6909 - acc: 0.6054 - val_loss: 0.6900 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6899 - acc: 0.6054 - val_loss: 0.6887 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6884 - acc: 0.6054 - val_loss: 0.6868 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6865 - acc: 0.6054 - val_loss: 0.6840 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6836 - acc: 0.6054 - val_loss: 0.6798 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6790 - acc: 0.6054 - val_loss: 0.6720 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6727 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6646 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6699 - acc: 0.6054 - val_loss: 0.6634 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6692 - acc: 0.6054 - val_loss: 0.6619 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6681 - acc: 0.6054 - val_loss: 0.6603 - val_acc: 0.6210\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6663 - acc: 0.6064 - val_loss: 0.6573 - val_acc: 0.6234\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6611 - acc: 0.6092 - val_loss: 0.6439 - val_acc: 0.6293\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6473 - acc: 0.6397 - val_loss: 0.6215 - val_acc: 0.6544\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6233 - acc: 0.6613 - val_loss: 0.5903 - val_acc: 0.6770\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5928 - acc: 0.6796 - val_loss: 0.5617 - val_acc: 0.7044\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5636 - acc: 0.7037 - val_loss: 0.5459 - val_acc: 0.7223\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.5466 - acc: 0.7161 - val_loss: 0.5363 - val_acc: 0.7330\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.5391 - acc: 0.7235 - val_loss: 0.5293 - val_acc: 0.7247\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.5277 - acc: 0.7312 - val_loss: 0.5211 - val_acc: 0.7402\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5205 - acc: 0.7413 - val_loss: 0.5154 - val_acc: 0.7449\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5130 - acc: 0.7427 - val_loss: 0.5125 - val_acc: 0.7414\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5082 - acc: 0.7469 - val_loss: 0.5077 - val_acc: 0.7449\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5040 - acc: 0.7509 - val_loss: 0.5041 - val_acc: 0.7509\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5027 - acc: 0.7483 - val_loss: 0.5022 - val_acc: 0.7473\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4964 - acc: 0.7530 - val_loss: 0.4982 - val_acc: 0.7533\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4932 - acc: 0.7541 - val_loss: 0.4964 - val_acc: 0.7497\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.4906 - acc: 0.7568 - val_loss: 0.4952 - val_acc: 0.7580\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4905 - acc: 0.7595 - val_loss: 0.4931 - val_acc: 0.7580\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.4868 - acc: 0.7581 - val_loss: 0.4906 - val_acc: 0.7592\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.4848 - acc: 0.7598 - val_loss: 0.4891 - val_acc: 0.7604\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.4837 - acc: 0.7624 - val_loss: 0.4876 - val_acc: 0.7616\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4812 - acc: 0.7615 - val_loss: 0.4882 - val_acc: 0.7628\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4807 - acc: 0.7642 - val_loss: 0.4849 - val_acc: 0.7664\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.4803 - acc: 0.7612 - val_loss: 0.4869 - val_acc: 0.7604\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4770 - acc: 0.7685 - val_loss: 0.4837 - val_acc: 0.7616\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4755 - acc: 0.7671 - val_loss: 0.4853 - val_acc: 0.7592\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4743 - acc: 0.7659 - val_loss: 0.4804 - val_acc: 0.7723\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4734 - acc: 0.7708 - val_loss: 0.4812 - val_acc: 0.7664\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4721 - acc: 0.7694 - val_loss: 0.4780 - val_acc: 0.7712\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4704 - acc: 0.7703 - val_loss: 0.4772 - val_acc: 0.7700\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4694 - acc: 0.7711 - val_loss: 0.4770 - val_acc: 0.7700\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4679 - acc: 0.7731 - val_loss: 0.4768 - val_acc: 0.7688\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4662 - acc: 0.7737 - val_loss: 0.4760 - val_acc: 0.7688\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4658 - acc: 0.7729 - val_loss: 0.4755 - val_acc: 0.7676\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4637 - acc: 0.7764 - val_loss: 0.4734 - val_acc: 0.7688\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4623 - acc: 0.7774 - val_loss: 0.4712 - val_acc: 0.7747\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4620 - acc: 0.7748 - val_loss: 0.4711 - val_acc: 0.7700\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4600 - acc: 0.7793 - val_loss: 0.4693 - val_acc: 0.7759\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4588 - acc: 0.7804 - val_loss: 0.4686 - val_acc: 0.7759\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4624 - acc: 0.7760 - val_loss: 0.4702 - val_acc: 0.7783\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4598 - acc: 0.7793 - val_loss: 0.4680 - val_acc: 0.7700\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4617 - acc: 0.7762 - val_loss: 0.4693 - val_acc: 0.7747\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4555 - acc: 0.7833 - val_loss: 0.4686 - val_acc: 0.7747\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4553 - acc: 0.7779 - val_loss: 0.4655 - val_acc: 0.7831\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4538 - acc: 0.7847 - val_loss: 0.4653 - val_acc: 0.7831\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4520 - acc: 0.7837 - val_loss: 0.4646 - val_acc: 0.7831\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4518 - acc: 0.7870 - val_loss: 0.4640 - val_acc: 0.7795\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4505 - acc: 0.7863 - val_loss: 0.4642 - val_acc: 0.7855\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4492 - acc: 0.7870 - val_loss: 0.4627 - val_acc: 0.7831\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4489 - acc: 0.7873 - val_loss: 0.4661 - val_acc: 0.7759\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4475 - acc: 0.7870 - val_loss: 0.4622 - val_acc: 0.7795\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4463 - acc: 0.7884 - val_loss: 0.4627 - val_acc: 0.7843\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4477 - acc: 0.7854 - val_loss: 0.4609 - val_acc: 0.7867\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4457 - acc: 0.7886 - val_loss: 0.4638 - val_acc: 0.7807\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4433 - acc: 0.7924 - val_loss: 0.4632 - val_acc: 0.7795\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4433 - acc: 0.7905 - val_loss: 0.4635 - val_acc: 0.7807\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4428 - acc: 0.7887 - val_loss: 0.4607 - val_acc: 0.7855\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4418 - acc: 0.7908 - val_loss: 0.4572 - val_acc: 0.7831\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4395 - acc: 0.7924 - val_loss: 0.4588 - val_acc: 0.7890\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4379 - acc: 0.7912 - val_loss: 0.4586 - val_acc: 0.7843\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4379 - acc: 0.7912 - val_loss: 0.4596 - val_acc: 0.7867\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4358 - acc: 0.7936 - val_loss: 0.4560 - val_acc: 0.7914\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4358 - acc: 0.7927 - val_loss: 0.4548 - val_acc: 0.7914\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4364 - acc: 0.7945 - val_loss: 0.4595 - val_acc: 0.7795\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4347 - acc: 0.7954 - val_loss: 0.4548 - val_acc: 0.7867\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4333 - acc: 0.7952 - val_loss: 0.4558 - val_acc: 0.7867\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4327 - acc: 0.7955 - val_loss: 0.4541 - val_acc: 0.7819\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4316 - acc: 0.7969 - val_loss: 0.4551 - val_acc: 0.7843\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4313 - acc: 0.7943 - val_loss: 0.4534 - val_acc: 0.7914\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4383 - acc: 0.7905 - val_loss: 0.4661 - val_acc: 0.7676\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4330 - acc: 0.7933 - val_loss: 0.4512 - val_acc: 0.7890\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4278 - acc: 0.7971 - val_loss: 0.4530 - val_acc: 0.7890\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4265 - acc: 0.7976 - val_loss: 0.4525 - val_acc: 0.7867\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4270 - acc: 0.8004 - val_loss: 0.4514 - val_acc: 0.7878\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4270 - acc: 0.7988 - val_loss: 0.4513 - val_acc: 0.7890\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4255 - acc: 0.8018 - val_loss: 0.4513 - val_acc: 0.7902\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4239 - acc: 0.8034 - val_loss: 0.4506 - val_acc: 0.7890\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4227 - acc: 0.8022 - val_loss: 0.4519 - val_acc: 0.7867\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4217 - acc: 0.8032 - val_loss: 0.4508 - val_acc: 0.7914\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4223 - acc: 0.8020 - val_loss: 0.4505 - val_acc: 0.7926\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4211 - acc: 0.8016 - val_loss: 0.4502 - val_acc: 0.7843\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4209 - acc: 0.8025 - val_loss: 0.4556 - val_acc: 0.7795\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4202 - acc: 0.8002 - val_loss: 0.4493 - val_acc: 0.7878\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4189 - acc: 0.8076 - val_loss: 0.4521 - val_acc: 0.7890\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4193 - acc: 0.8058 - val_loss: 0.4519 - val_acc: 0.7926\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4188 - acc: 0.8051 - val_loss: 0.4525 - val_acc: 0.7795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:05:31,923]\u001B[0m Trial 2 finished with value: 0.7794994115829468 and parameters: {'lstm_first_layer_size': 196, 'learning_rate': 1.0726800382715764e-05}. Best is trial 2 with value: 0.7794994115829468.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         905800    \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 100)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      40100     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               80400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,026,401\n",
      "Trainable params: 120,601\n",
      "Non-trainable params: 905,800\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 30ms/step - loss: nan - acc: 0.6055 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:06:08,758]\u001B[0m Trial 3 finished with value: 0.6185935735702515 and parameters: {'lstm_first_layer_size': 100, 'learning_rate': 0.07039659154768411}. Best is trial 2 with value: 0.7794994115829468.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         905800    \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 100)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      40100     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 169)               182520    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,128,590\n",
      "Trainable params: 222,790\n",
      "Non-trainable params: 905,800\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 32ms/step - loss: 0.7428 - acc: 0.6059 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6659 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6663 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6661 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6717 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6667 - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:06:48,211]\u001B[0m Trial 4 finished with value: 0.6185935735702515 and parameters: {'lstm_first_layer_size': 169, 'learning_rate': 0.0053625356008351905}. Best is trial 2 with value: 0.7794994115829468.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value:  0.7794994115829468\n",
      "clean+lemmas+no_stopwords nkjp+wiki-lemmas-all-100-skipg-hs.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:06:48,710]\u001B[0m A new study created in RDB with name: no-name-681ce05e-c563-4aa5-b63e-a07c555d1714\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8925, 100)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         892500    \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 100)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      40100     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 122)               108824    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 123       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,041,547\n",
      "Trainable params: 149,047\n",
      "Non-trainable params: 892,500\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 32ms/step - loss: nan - acc: 0.5879 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: nan - acc: 0.6054 - val_loss: nan - val_acc: 0.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:07:23,425]\u001B[0m Trial 0 finished with value: 0.6185935735702515 and parameters: {'lstm_first_layer_size': 122, 'learning_rate': 0.06665087739981983}. Best is trial 0 with value: 0.6185935735702515.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         892500    \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 100)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      40100     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 22)                10824     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 23        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 943,447\n",
      "Trainable params: 50,947\n",
      "Non-trainable params: 892,500\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 27ms/step - loss: 0.7085 - acc: 0.6054 - val_loss: 0.6669 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6718 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6687 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6724 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6685 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6717 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6725 - acc: 0.6054 - val_loss: 0.6662 - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6717 - acc: 0.6054 - val_loss: 0.6647 - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6659 - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6647 - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6667 - val_acc: 0.6186\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6721 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6670 - val_acc: 0.6186\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6665 - val_acc: 0.6186\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6666 - val_acc: 0.6186\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6707 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6672 - val_acc: 0.6186\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6719 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6664 - val_acc: 0.6186\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6662 - val_acc: 0.6186\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6707 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6664 - val_acc: 0.6186\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6647 - val_acc: 0.6186\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6662 - val_acc: 0.6186\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6647 - val_acc: 0.6186\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6661 - val_acc: 0.6186\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6659 - val_acc: 0.6186\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6717 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6673 - val_acc: 0.6186\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6663 - val_acc: 0.6186\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6670 - val_acc: 0.6186\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6717 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:07:51,986]\u001B[0m Trial 1 finished with value: 0.6185935735702515 and parameters: {'lstm_first_layer_size': 22, 'learning_rate': 0.05430944904281446}. Best is trial 0 with value: 0.6185935735702515.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         892500    \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 100)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      40100     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 153)               155448    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 154       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,088,202\n",
      "Trainable params: 195,702\n",
      "Non-trainable params: 892,500\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 32ms/step - loss: 0.6754 - acc: 0.6055 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6674 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6683 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6671 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6663 - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6668 - val_acc: 0.6186\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6659 - val_acc: 0.6186\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6659 - val_acc: 0.6186\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:08:29,934]\u001B[0m Trial 2 finished with value: 0.6185935735702515 and parameters: {'lstm_first_layer_size': 153, 'learning_rate': 0.0009885197355413715}. Best is trial 0 with value: 0.6185935735702515.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         892500    \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 100)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      40100     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 199)               238800    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 200       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,171,600\n",
      "Trainable params: 279,100\n",
      "Non-trainable params: 892,500\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 30ms/step - loss: 0.6927 - acc: 0.6054 - val_loss: 0.6920 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6915 - acc: 0.6054 - val_loss: 0.6904 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6898 - acc: 0.6054 - val_loss: 0.6880 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6870 - acc: 0.6054 - val_loss: 0.6836 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6815 - acc: 0.6054 - val_loss: 0.6738 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6717 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6663 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6706 - acc: 0.6054 - val_loss: 0.6643 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6707 - acc: 0.6054 - val_loss: 0.6639 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6697 - acc: 0.6054 - val_loss: 0.6628 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6688 - acc: 0.6052 - val_loss: 0.6608 - val_acc: 0.6222\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6654 - acc: 0.6082 - val_loss: 0.6528 - val_acc: 0.6222\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6565 - acc: 0.6275 - val_loss: 0.6412 - val_acc: 0.6424\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6434 - acc: 0.6512 - val_loss: 0.6129 - val_acc: 0.6687\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6126 - acc: 0.6801 - val_loss: 0.5690 - val_acc: 0.7020\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5646 - acc: 0.7079 - val_loss: 0.5227 - val_acc: 0.7414\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5289 - acc: 0.7361 - val_loss: 0.5120 - val_acc: 0.7557\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5173 - acc: 0.7439 - val_loss: 0.5059 - val_acc: 0.7545\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5088 - acc: 0.7537 - val_loss: 0.4976 - val_acc: 0.7616\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.5013 - acc: 0.7560 - val_loss: 0.4937 - val_acc: 0.7676\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4950 - acc: 0.7582 - val_loss: 0.4962 - val_acc: 0.7628\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4931 - acc: 0.7605 - val_loss: 0.4871 - val_acc: 0.7771\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4864 - acc: 0.7636 - val_loss: 0.4842 - val_acc: 0.7747\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4828 - acc: 0.7633 - val_loss: 0.4869 - val_acc: 0.7628\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4794 - acc: 0.7642 - val_loss: 0.4803 - val_acc: 0.7735\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4778 - acc: 0.7659 - val_loss: 0.4793 - val_acc: 0.7759\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4807 - acc: 0.7640 - val_loss: 0.4882 - val_acc: 0.7545\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4725 - acc: 0.7708 - val_loss: 0.4812 - val_acc: 0.7628\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4710 - acc: 0.7701 - val_loss: 0.4751 - val_acc: 0.7783\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4672 - acc: 0.7685 - val_loss: 0.4716 - val_acc: 0.7723\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4643 - acc: 0.7739 - val_loss: 0.4741 - val_acc: 0.7771\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4623 - acc: 0.7722 - val_loss: 0.4683 - val_acc: 0.7795\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4610 - acc: 0.7755 - val_loss: 0.4733 - val_acc: 0.7759\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4576 - acc: 0.7755 - val_loss: 0.4719 - val_acc: 0.7783\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4573 - acc: 0.7750 - val_loss: 0.4685 - val_acc: 0.7771\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4547 - acc: 0.7779 - val_loss: 0.4643 - val_acc: 0.7783\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4516 - acc: 0.7795 - val_loss: 0.4655 - val_acc: 0.7759\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4507 - acc: 0.7790 - val_loss: 0.4638 - val_acc: 0.7819\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4486 - acc: 0.7816 - val_loss: 0.4608 - val_acc: 0.7795\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4475 - acc: 0.7826 - val_loss: 0.4617 - val_acc: 0.7795\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4439 - acc: 0.7840 - val_loss: 0.4620 - val_acc: 0.7783\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4457 - acc: 0.7858 - val_loss: 0.4571 - val_acc: 0.7831\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4447 - acc: 0.7856 - val_loss: 0.4571 - val_acc: 0.7807\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.4402 - acc: 0.7886 - val_loss: 0.4555 - val_acc: 0.7807\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4374 - acc: 0.7889 - val_loss: 0.4555 - val_acc: 0.7819\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4357 - acc: 0.7884 - val_loss: 0.4631 - val_acc: 0.7807\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4356 - acc: 0.7921 - val_loss: 0.4527 - val_acc: 0.7819\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4328 - acc: 0.7936 - val_loss: 0.4519 - val_acc: 0.7783\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4325 - acc: 0.7941 - val_loss: 0.4595 - val_acc: 0.7902\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4316 - acc: 0.7934 - val_loss: 0.4503 - val_acc: 0.7807\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4277 - acc: 0.7959 - val_loss: 0.4523 - val_acc: 0.7914\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.4272 - acc: 0.7980 - val_loss: 0.4491 - val_acc: 0.7783\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4251 - acc: 0.7982 - val_loss: 0.4580 - val_acc: 0.7926\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4243 - acc: 0.7975 - val_loss: 0.4465 - val_acc: 0.7831\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4266 - acc: 0.7997 - val_loss: 0.4530 - val_acc: 0.7974\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4182 - acc: 0.8013 - val_loss: 0.4486 - val_acc: 0.7831\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4171 - acc: 0.8062 - val_loss: 0.4538 - val_acc: 0.7926\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4172 - acc: 0.8069 - val_loss: 0.4474 - val_acc: 0.7855\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4117 - acc: 0.8062 - val_loss: 0.4476 - val_acc: 0.7902\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4102 - acc: 0.8097 - val_loss: 0.4479 - val_acc: 0.7843\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4090 - acc: 0.8081 - val_loss: 0.4462 - val_acc: 0.7843\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4114 - acc: 0.8083 - val_loss: 0.4436 - val_acc: 0.7878\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4067 - acc: 0.8156 - val_loss: 0.4666 - val_acc: 0.7998\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4091 - acc: 0.8123 - val_loss: 0.4478 - val_acc: 0.7938\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4035 - acc: 0.8154 - val_loss: 0.4554 - val_acc: 0.7998\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4089 - acc: 0.8133 - val_loss: 0.4410 - val_acc: 0.7926\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4000 - acc: 0.8156 - val_loss: 0.4471 - val_acc: 0.7914\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.3989 - acc: 0.8175 - val_loss: 0.4494 - val_acc: 0.7950\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.3945 - acc: 0.8196 - val_loss: 0.4662 - val_acc: 0.7962\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.3939 - acc: 0.8224 - val_loss: 0.4461 - val_acc: 0.7962\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.3918 - acc: 0.8231 - val_loss: 0.4458 - val_acc: 0.7986\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.3913 - acc: 0.8219 - val_loss: 0.4495 - val_acc: 0.7974\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.3880 - acc: 0.8264 - val_loss: 0.4482 - val_acc: 0.7986\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.3888 - acc: 0.8273 - val_loss: 0.4424 - val_acc: 0.7998\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.3851 - acc: 0.8271 - val_loss: 0.4457 - val_acc: 0.7974\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.3859 - acc: 0.8281 - val_loss: 0.4417 - val_acc: 0.8021\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.3862 - acc: 0.8294 - val_loss: 0.4370 - val_acc: 0.7974\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.3820 - acc: 0.8290 - val_loss: 0.4524 - val_acc: 0.8057\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.3789 - acc: 0.8321 - val_loss: 0.4451 - val_acc: 0.8033\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.3768 - acc: 0.8362 - val_loss: 0.4437 - val_acc: 0.8045\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.3773 - acc: 0.8328 - val_loss: 0.4486 - val_acc: 0.8069\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.3747 - acc: 0.8362 - val_loss: 0.4475 - val_acc: 0.8081\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.3724 - acc: 0.8379 - val_loss: 0.4411 - val_acc: 0.8105\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.3705 - acc: 0.8393 - val_loss: 0.4408 - val_acc: 0.8081\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.3743 - acc: 0.8360 - val_loss: 0.4433 - val_acc: 0.8081\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.3723 - acc: 0.8379 - val_loss: 0.4612 - val_acc: 0.8010\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.3696 - acc: 0.8402 - val_loss: 0.4453 - val_acc: 0.8105\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.3685 - acc: 0.8403 - val_loss: 0.4421 - val_acc: 0.8129\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.3635 - acc: 0.8436 - val_loss: 0.4521 - val_acc: 0.8081\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.3648 - acc: 0.8410 - val_loss: 0.4374 - val_acc: 0.8093\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.3688 - acc: 0.8410 - val_loss: 0.4344 - val_acc: 0.8045\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.3641 - acc: 0.8442 - val_loss: 0.4370 - val_acc: 0.8164\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.3632 - acc: 0.8440 - val_loss: 0.4417 - val_acc: 0.8117\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.3622 - acc: 0.8461 - val_loss: 0.4352 - val_acc: 0.8105\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.3580 - acc: 0.8466 - val_loss: 0.4426 - val_acc: 0.8164\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.3553 - acc: 0.8503 - val_loss: 0.4443 - val_acc: 0.8141\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.3566 - acc: 0.8491 - val_loss: 0.4527 - val_acc: 0.8117\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.3534 - acc: 0.8494 - val_loss: 0.4483 - val_acc: 0.8117\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.3515 - acc: 0.8518 - val_loss: 0.4424 - val_acc: 0.8129\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.3524 - acc: 0.8504 - val_loss: 0.4430 - val_acc: 0.8188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:09:10,577]\u001B[0m Trial 3 finished with value: 0.8188319206237793 and parameters: {'lstm_first_layer_size': 199, 'learning_rate': 2.0770171730839946e-05}. Best is trial 3 with value: 0.8188319206237793.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         892500    \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 100)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      40100     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 253)               358248    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 254       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,291,102\n",
      "Trainable params: 398,602\n",
      "Non-trainable params: 892,500\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 4s 36ms/step - loss: 0.7093 - acc: 0.6055 - val_loss: 0.6659 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6672 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6718 - acc: 0.6054 - val_loss: 0.6675 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6695 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6720 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6663 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6717 - acc: 0.6054 - val_loss: 0.6665 - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6661 - val_acc: 0.6186\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6720 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6719 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:09:57,278]\u001B[0m Trial 4 finished with value: 0.6185935735702515 and parameters: {'lstm_first_layer_size': 253, 'learning_rate': 0.0060537753862322866}. Best is trial 3 with value: 0.8188319206237793.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value:  0.8188319206237793\n",
      "lemmas+no_stopwords nkjp+wiki-lemmas-all-100-skipg-hs.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:09:57,761]\u001B[0m A new study created in RDB with name: no-name-70c24a1a-6a93-4fa8-90cb-5b68a5fc2d96\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8927, 100)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         892700    \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 100)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      40100     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 44)                25520     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 958,365\n",
      "Trainable params: 65,665\n",
      "Non-trainable params: 892,700\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 26ms/step - loss: 0.6757 - acc: 0.6047 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6718 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6661 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6659 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6721 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6659 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:10:27,292]\u001B[0m Trial 0 finished with value: 0.6185935735702515 and parameters: {'lstm_first_layer_size': 44, 'learning_rate': 0.004142640999569477}. Best is trial 0 with value: 0.6185935735702515.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         892700    \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 100)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      40100     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                42240     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 975,105\n",
      "Trainable params: 82,405\n",
      "Non-trainable params: 892,700\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 31ms/step - loss: 0.6919 - acc: 0.6059 - val_loss: 0.6900 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6884 - acc: 0.6054 - val_loss: 0.6848 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6822 - acc: 0.6054 - val_loss: 0.6753 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6730 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6707 - acc: 0.6054 - val_loss: 0.6647 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6707 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6707 - acc: 0.6054 - val_loss: 0.6646 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6707 - acc: 0.6054 - val_loss: 0.6645 - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6706 - acc: 0.6054 - val_loss: 0.6646 - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6707 - acc: 0.6054 - val_loss: 0.6646 - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6703 - acc: 0.6054 - val_loss: 0.6640 - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6702 - acc: 0.6054 - val_loss: 0.6639 - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6700 - acc: 0.6054 - val_loss: 0.6635 - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6701 - acc: 0.6054 - val_loss: 0.6621 - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6692 - acc: 0.6057 - val_loss: 0.6607 - val_acc: 0.6222\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6637 - acc: 0.6108 - val_loss: 0.6489 - val_acc: 0.6222\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6258 - acc: 0.6416 - val_loss: 0.5423 - val_acc: 0.7116\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.5463 - acc: 0.7183 - val_loss: 0.5148 - val_acc: 0.7366\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.5057 - acc: 0.7492 - val_loss: 0.4832 - val_acc: 0.7676\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.4883 - acc: 0.7546 - val_loss: 0.4834 - val_acc: 0.7628\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.4698 - acc: 0.7701 - val_loss: 0.4607 - val_acc: 0.7795\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.4565 - acc: 0.7734 - val_loss: 0.4582 - val_acc: 0.7855\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.4525 - acc: 0.7776 - val_loss: 0.4518 - val_acc: 0.7771\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.4444 - acc: 0.7826 - val_loss: 0.4484 - val_acc: 0.7962\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.4414 - acc: 0.7818 - val_loss: 0.4476 - val_acc: 0.7747\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.4350 - acc: 0.7875 - val_loss: 0.4459 - val_acc: 0.7890\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.4382 - acc: 0.7835 - val_loss: 0.4605 - val_acc: 0.7783\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.4265 - acc: 0.7887 - val_loss: 0.4387 - val_acc: 0.7926\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.4185 - acc: 0.7943 - val_loss: 0.4349 - val_acc: 0.7926\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.4142 - acc: 0.7950 - val_loss: 0.4372 - val_acc: 0.7962\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.4115 - acc: 0.7971 - val_loss: 0.4312 - val_acc: 0.7962\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.4063 - acc: 0.7999 - val_loss: 0.4354 - val_acc: 0.7974\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.4039 - acc: 0.8023 - val_loss: 0.4265 - val_acc: 0.7986\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.3973 - acc: 0.8067 - val_loss: 0.4270 - val_acc: 0.8069\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.3999 - acc: 0.8011 - val_loss: 0.4231 - val_acc: 0.8010\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.3944 - acc: 0.8058 - val_loss: 0.4282 - val_acc: 0.7962\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.3910 - acc: 0.8088 - val_loss: 0.4240 - val_acc: 0.8069\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.3847 - acc: 0.8138 - val_loss: 0.4213 - val_acc: 0.8021\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.3808 - acc: 0.8142 - val_loss: 0.4310 - val_acc: 0.8033\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.3794 - acc: 0.8178 - val_loss: 0.4164 - val_acc: 0.8021\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.3756 - acc: 0.8178 - val_loss: 0.4203 - val_acc: 0.8045\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.3725 - acc: 0.8187 - val_loss: 0.4187 - val_acc: 0.8057\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.3725 - acc: 0.8198 - val_loss: 0.4112 - val_acc: 0.8081\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.3668 - acc: 0.8213 - val_loss: 0.4105 - val_acc: 0.8141\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.3677 - acc: 0.8210 - val_loss: 0.4174 - val_acc: 0.8021\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.3607 - acc: 0.8257 - val_loss: 0.4119 - val_acc: 0.8081\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.3562 - acc: 0.8290 - val_loss: 0.4120 - val_acc: 0.8045\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.3592 - acc: 0.8267 - val_loss: 0.4228 - val_acc: 0.8164\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.3540 - acc: 0.8273 - val_loss: 0.4076 - val_acc: 0.8141\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.3494 - acc: 0.8302 - val_loss: 0.4037 - val_acc: 0.8141\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.3418 - acc: 0.8367 - val_loss: 0.4068 - val_acc: 0.8129\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.3414 - acc: 0.8365 - val_loss: 0.4176 - val_acc: 0.8010\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.3478 - acc: 0.8339 - val_loss: 0.4068 - val_acc: 0.8141\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.3374 - acc: 0.8391 - val_loss: 0.4035 - val_acc: 0.8105\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.3355 - acc: 0.8386 - val_loss: 0.4176 - val_acc: 0.8212\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.3374 - acc: 0.8374 - val_loss: 0.4038 - val_acc: 0.8188\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.3295 - acc: 0.8419 - val_loss: 0.4268 - val_acc: 0.8200\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.3264 - acc: 0.8464 - val_loss: 0.4139 - val_acc: 0.8176\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.3248 - acc: 0.8447 - val_loss: 0.4178 - val_acc: 0.8153\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.3219 - acc: 0.8475 - val_loss: 0.4256 - val_acc: 0.8236\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.3171 - acc: 0.8504 - val_loss: 0.4224 - val_acc: 0.8188\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.3177 - acc: 0.8456 - val_loss: 0.4394 - val_acc: 0.8200\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.3095 - acc: 0.8550 - val_loss: 0.4399 - val_acc: 0.8176\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.3057 - acc: 0.8571 - val_loss: 0.4467 - val_acc: 0.8153\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.3058 - acc: 0.8564 - val_loss: 0.4435 - val_acc: 0.8129\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.3092 - acc: 0.8534 - val_loss: 0.4484 - val_acc: 0.8081\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.3136 - acc: 0.8524 - val_loss: 0.4290 - val_acc: 0.8129\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.3023 - acc: 0.8572 - val_loss: 0.4341 - val_acc: 0.8212\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.2926 - acc: 0.8613 - val_loss: 0.4307 - val_acc: 0.8236\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.2921 - acc: 0.8619 - val_loss: 0.4352 - val_acc: 0.8164\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.2866 - acc: 0.8639 - val_loss: 0.4534 - val_acc: 0.8200\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.2884 - acc: 0.8628 - val_loss: 0.4393 - val_acc: 0.8188\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.2810 - acc: 0.8658 - val_loss: 0.4382 - val_acc: 0.8224\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.2767 - acc: 0.8698 - val_loss: 0.4492 - val_acc: 0.8248\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.2824 - acc: 0.8661 - val_loss: 0.4759 - val_acc: 0.8069\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.2873 - acc: 0.8637 - val_loss: 0.4354 - val_acc: 0.8153\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.2816 - acc: 0.8703 - val_loss: 0.4395 - val_acc: 0.8236\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.2698 - acc: 0.8750 - val_loss: 0.4607 - val_acc: 0.8188\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.2658 - acc: 0.8754 - val_loss: 0.5075 - val_acc: 0.8153\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.2681 - acc: 0.8714 - val_loss: 0.4583 - val_acc: 0.8188\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.2633 - acc: 0.8783 - val_loss: 0.4762 - val_acc: 0.8236\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.2553 - acc: 0.8806 - val_loss: 0.4660 - val_acc: 0.8153\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.2564 - acc: 0.8804 - val_loss: 0.4610 - val_acc: 0.8153\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.2609 - acc: 0.8799 - val_loss: 0.4778 - val_acc: 0.8188\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.2553 - acc: 0.8834 - val_loss: 0.4806 - val_acc: 0.8212\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.2628 - acc: 0.8782 - val_loss: 0.4635 - val_acc: 0.8045\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.2542 - acc: 0.8876 - val_loss: 0.4853 - val_acc: 0.8212\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.2442 - acc: 0.8919 - val_loss: 0.5257 - val_acc: 0.8224\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.2823 - acc: 0.8660 - val_loss: 0.4676 - val_acc: 0.8200\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.2444 - acc: 0.8891 - val_loss: 0.4821 - val_acc: 0.8236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:10:59,755]\u001B[0m Trial 1 finished with value: 0.8235995173454285 and parameters: {'lstm_first_layer_size': 64, 'learning_rate': 8.403908876144988e-05}. Best is trial 1 with value: 0.8235995173454285.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         892700    \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 100)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      40100     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 46)                27048     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 47        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 959,895\n",
      "Trainable params: 67,195\n",
      "Non-trainable params: 892,700\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 25ms/step - loss: 0.6735 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6664 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6723 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6647 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6672 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6661 - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6707 - acc: 0.6054 - val_loss: 0.6664 - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6733 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6719 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6672 - val_acc: 0.6186\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6672 - val_acc: 0.6186\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6726 - acc: 0.6054 - val_loss: 0.6662 - val_acc: 0.6186\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6659 - val_acc: 0.6186\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6659 - val_acc: 0.6186\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6666 - val_acc: 0.6186\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6663 - val_acc: 0.6186\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6661 - val_acc: 0.6186\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6719 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6677 - val_acc: 0.6186\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6670 - val_acc: 0.6186\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6662 - val_acc: 0.6186\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6661 - val_acc: 0.6186\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6659 - val_acc: 0.6186\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6727 - acc: 0.6054 - val_loss: 0.6663 - val_acc: 0.6186\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:11:27,439]\u001B[0m Trial 2 finished with value: 0.6185935735702515 and parameters: {'lstm_first_layer_size': 46, 'learning_rate': 0.052076653088066735}. Best is trial 1 with value: 0.8235995173454285.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         892700    \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 100)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      40100     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 67)                45024     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 68        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 977,892\n",
      "Trainable params: 85,192\n",
      "Non-trainable params: 892,700\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 27ms/step - loss: 0.6775 - acc: 0.5872 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6665 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6719 - acc: 0.6054 - val_loss: 0.6679 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6665 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6707 - acc: 0.6054 - val_loss: 0.6662 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6707 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6675 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6721 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6661 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6679 - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6662 - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6717 - acc: 0.6054 - val_loss: 0.6690 - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6718 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6721 - acc: 0.6054 - val_loss: 0.6674 - val_acc: 0.6186\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6671 - val_acc: 0.6186\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6720 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6717 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6662 - val_acc: 0.6186\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6681 - val_acc: 0.6186\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6688 - val_acc: 0.6186\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6720 - acc: 0.6054 - val_loss: 0.6677 - val_acc: 0.6186\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6720 - acc: 0.6054 - val_loss: 0.6682 - val_acc: 0.6186\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6662 - val_acc: 0.6186\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6669 - val_acc: 0.6186\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6668 - val_acc: 0.6186\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6719 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6666 - val_acc: 0.6186\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6722 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6677 - val_acc: 0.6186\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6719 - acc: 0.6054 - val_loss: 0.6665 - val_acc: 0.6186\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:12:00,355]\u001B[0m Trial 3 finished with value: 0.6185935735702515 and parameters: {'lstm_first_layer_size': 67, 'learning_rate': 0.0809135520841377}. Best is trial 1 with value: 0.8235995173454285.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         892700    \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 100)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      40100     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 28)                14448     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 29        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 947,277\n",
      "Trainable params: 54,577\n",
      "Non-trainable params: 892,700\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 25ms/step - loss: 0.6930 - acc: 0.6054 - val_loss: 0.6927 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6926 - acc: 0.6054 - val_loss: 0.6922 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6921 - acc: 0.6054 - val_loss: 0.6917 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6917 - acc: 0.6054 - val_loss: 0.6912 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6912 - acc: 0.6054 - val_loss: 0.6906 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6907 - acc: 0.6054 - val_loss: 0.6900 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6901 - acc: 0.6054 - val_loss: 0.6894 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6896 - acc: 0.6054 - val_loss: 0.6887 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6890 - acc: 0.6054 - val_loss: 0.6881 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6884 - acc: 0.6054 - val_loss: 0.6874 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6877 - acc: 0.6054 - val_loss: 0.6866 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6871 - acc: 0.6054 - val_loss: 0.6858 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6864 - acc: 0.6054 - val_loss: 0.6850 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6857 - acc: 0.6054 - val_loss: 0.6842 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6849 - acc: 0.6054 - val_loss: 0.6833 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6842 - acc: 0.6054 - val_loss: 0.6824 - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6834 - acc: 0.6054 - val_loss: 0.6815 - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6825 - acc: 0.6054 - val_loss: 0.6805 - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6817 - acc: 0.6054 - val_loss: 0.6795 - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6808 - acc: 0.6054 - val_loss: 0.6785 - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6800 - acc: 0.6054 - val_loss: 0.6773 - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6791 - acc: 0.6054 - val_loss: 0.6763 - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6782 - acc: 0.6054 - val_loss: 0.6753 - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6773 - acc: 0.6054 - val_loss: 0.6742 - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6765 - acc: 0.6054 - val_loss: 0.6731 - val_acc: 0.6186\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6757 - acc: 0.6054 - val_loss: 0.6721 - val_acc: 0.6186\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6749 - acc: 0.6054 - val_loss: 0.6711 - val_acc: 0.6186\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6741 - acc: 0.6054 - val_loss: 0.6701 - val_acc: 0.6186\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6735 - acc: 0.6054 - val_loss: 0.6693 - val_acc: 0.6186\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6728 - acc: 0.6054 - val_loss: 0.6685 - val_acc: 0.6186\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6723 - acc: 0.6054 - val_loss: 0.6677 - val_acc: 0.6186\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6718 - acc: 0.6054 - val_loss: 0.6671 - val_acc: 0.6186\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6666 - val_acc: 0.6186\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6662 - val_acc: 0.6186\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:12:28,641]\u001B[0m Trial 4 finished with value: 0.6185935735702515 and parameters: {'lstm_first_layer_size': 28, 'learning_rate': 1.212967348897448e-05}. Best is trial 1 with value: 0.8235995173454285.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value:  0.8235995173454285\n",
      "nkjp+wiki-lemmas-all-300-cbow-hs.txt\n",
      "clean+lemmas nkjp+wiki-lemmas-all-300-cbow-hs.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:15:48,978]\u001B[0m A new study created in RDB with name: no-name-5307fe91-41e8-47e1-8ca5-aa49cd6ac595\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9403, 300)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 300)         2820900   \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 300)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      120100    \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 196)               232848    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 197       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,174,045\n",
      "Trainable params: 353,145\n",
      "Non-trainable params: 2,820,900\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 37ms/step - loss: 0.6929 - acc: 0.6052 - val_loss: 0.6925 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6922 - acc: 0.6054 - val_loss: 0.6917 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.6914 - acc: 0.6054 - val_loss: 0.6906 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6904 - acc: 0.6054 - val_loss: 0.6893 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.6890 - acc: 0.6054 - val_loss: 0.6874 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.6870 - acc: 0.6054 - val_loss: 0.6844 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.6838 - acc: 0.6054 - val_loss: 0.6795 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.6781 - acc: 0.6054 - val_loss: 0.6707 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6717 - acc: 0.6054 - val_loss: 0.6633 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6672 - acc: 0.6054 - val_loss: 0.6577 - val_acc: 0.6210\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.6469 - acc: 0.6082 - val_loss: 0.6007 - val_acc: 0.6365\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.5867 - acc: 0.6653 - val_loss: 0.5684 - val_acc: 0.6782\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 1s 28ms/step - loss: 0.5509 - acc: 0.7040 - val_loss: 0.5467 - val_acc: 0.6973\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.5281 - acc: 0.7229 - val_loss: 0.5337 - val_acc: 0.7175\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 1s 26ms/step - loss: 0.5112 - acc: 0.7392 - val_loss: 0.5243 - val_acc: 0.7271\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.4990 - acc: 0.7471 - val_loss: 0.5174 - val_acc: 0.7330\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4887 - acc: 0.7551 - val_loss: 0.5095 - val_acc: 0.7402\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.4815 - acc: 0.7596 - val_loss: 0.5050 - val_acc: 0.7449\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.4732 - acc: 0.7657 - val_loss: 0.4999 - val_acc: 0.7485\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.4668 - acc: 0.7710 - val_loss: 0.5000 - val_acc: 0.7509\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.4634 - acc: 0.7746 - val_loss: 0.4896 - val_acc: 0.7616\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4520 - acc: 0.7844 - val_loss: 0.4908 - val_acc: 0.7592\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.4483 - acc: 0.7861 - val_loss: 0.4832 - val_acc: 0.7640\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.4397 - acc: 0.7872 - val_loss: 0.4819 - val_acc: 0.7688\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.4358 - acc: 0.7924 - val_loss: 0.4774 - val_acc: 0.7664\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.4291 - acc: 0.7975 - val_loss: 0.4779 - val_acc: 0.7723\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.4235 - acc: 0.7987 - val_loss: 0.4815 - val_acc: 0.7700\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4197 - acc: 0.8025 - val_loss: 0.4851 - val_acc: 0.7688\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.4137 - acc: 0.8058 - val_loss: 0.4786 - val_acc: 0.7747\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.4107 - acc: 0.8091 - val_loss: 0.4746 - val_acc: 0.7723\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.4052 - acc: 0.8159 - val_loss: 0.4958 - val_acc: 0.7747\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.4026 - acc: 0.8152 - val_loss: 0.4764 - val_acc: 0.7723\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.3996 - acc: 0.8175 - val_loss: 0.4987 - val_acc: 0.7759\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.3923 - acc: 0.8194 - val_loss: 0.4777 - val_acc: 0.7652\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.3871 - acc: 0.8259 - val_loss: 0.4925 - val_acc: 0.7700\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.3827 - acc: 0.8292 - val_loss: 0.5012 - val_acc: 0.7723\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.3799 - acc: 0.8295 - val_loss: 0.5017 - val_acc: 0.7712\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.3749 - acc: 0.8327 - val_loss: 0.4906 - val_acc: 0.7688\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.3715 - acc: 0.8367 - val_loss: 0.4937 - val_acc: 0.7700\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.3680 - acc: 0.8395 - val_loss: 0.5148 - val_acc: 0.7652\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.3640 - acc: 0.8445 - val_loss: 0.5060 - val_acc: 0.7688\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.3579 - acc: 0.8485 - val_loss: 0.5065 - val_acc: 0.7712\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.3548 - acc: 0.8475 - val_loss: 0.5127 - val_acc: 0.7723\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.3531 - acc: 0.8511 - val_loss: 0.5040 - val_acc: 0.7688\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.3520 - acc: 0.8506 - val_loss: 0.5063 - val_acc: 0.7759\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.3495 - acc: 0.8513 - val_loss: 0.5217 - val_acc: 0.7712\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.3409 - acc: 0.8590 - val_loss: 0.5212 - val_acc: 0.7735\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.3385 - acc: 0.8630 - val_loss: 0.5340 - val_acc: 0.7712\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.3363 - acc: 0.8613 - val_loss: 0.5293 - val_acc: 0.7700\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.3320 - acc: 0.8658 - val_loss: 0.5289 - val_acc: 0.7700\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.3291 - acc: 0.8677 - val_loss: 0.5396 - val_acc: 0.7783\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.3272 - acc: 0.8689 - val_loss: 0.5260 - val_acc: 0.7747\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.3253 - acc: 0.8712 - val_loss: 0.5284 - val_acc: 0.7771\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.3224 - acc: 0.8717 - val_loss: 0.5478 - val_acc: 0.7819\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.3209 - acc: 0.8728 - val_loss: 0.5358 - val_acc: 0.7807\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.3191 - acc: 0.8740 - val_loss: 0.5297 - val_acc: 0.7783\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.3122 - acc: 0.8787 - val_loss: 0.5398 - val_acc: 0.7783\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.3112 - acc: 0.8783 - val_loss: 0.5436 - val_acc: 0.7795\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.3070 - acc: 0.8809 - val_loss: 0.5397 - val_acc: 0.7783\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.3078 - acc: 0.8803 - val_loss: 0.5556 - val_acc: 0.7819\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.3037 - acc: 0.8832 - val_loss: 0.5553 - val_acc: 0.7890\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.3002 - acc: 0.8867 - val_loss: 0.5527 - val_acc: 0.7807\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.3000 - acc: 0.8860 - val_loss: 0.5489 - val_acc: 0.7819\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.2971 - acc: 0.8874 - val_loss: 0.5526 - val_acc: 0.7831\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2948 - acc: 0.8888 - val_loss: 0.5548 - val_acc: 0.7878\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.2929 - acc: 0.8911 - val_loss: 0.5493 - val_acc: 0.7867\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.2988 - acc: 0.8858 - val_loss: 0.5546 - val_acc: 0.7938\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.2907 - acc: 0.8923 - val_loss: 0.5670 - val_acc: 0.7867\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.2918 - acc: 0.8904 - val_loss: 0.5513 - val_acc: 0.7867\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2883 - acc: 0.8935 - val_loss: 0.5680 - val_acc: 0.7867\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.2859 - acc: 0.8947 - val_loss: 0.5588 - val_acc: 0.7914\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.2855 - acc: 0.8951 - val_loss: 0.5596 - val_acc: 0.7867\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2849 - acc: 0.8959 - val_loss: 0.5680 - val_acc: 0.7890\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.2870 - acc: 0.8942 - val_loss: 0.5708 - val_acc: 0.7878\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2831 - acc: 0.8963 - val_loss: 0.5806 - val_acc: 0.7867\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2828 - acc: 0.8963 - val_loss: 0.5549 - val_acc: 0.7890\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2826 - acc: 0.8961 - val_loss: 0.5545 - val_acc: 0.7878\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2838 - acc: 0.8951 - val_loss: 0.5603 - val_acc: 0.7902\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.2808 - acc: 0.8973 - val_loss: 0.5665 - val_acc: 0.7855\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2807 - acc: 0.8968 - val_loss: 0.5707 - val_acc: 0.7926\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.2793 - acc: 0.8980 - val_loss: 0.5619 - val_acc: 0.7855\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2787 - acc: 0.8979 - val_loss: 0.5592 - val_acc: 0.7843\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2924 - acc: 0.8876 - val_loss: 0.5867 - val_acc: 0.7902\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.2824 - acc: 0.8961 - val_loss: 0.5923 - val_acc: 0.7902\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2777 - acc: 0.8979 - val_loss: 0.5650 - val_acc: 0.7878\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.2803 - acc: 0.8975 - val_loss: 0.5588 - val_acc: 0.7855\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.2799 - acc: 0.8982 - val_loss: 0.5551 - val_acc: 0.7867\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.2790 - acc: 0.8970 - val_loss: 0.5610 - val_acc: 0.7831\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2790 - acc: 0.8968 - val_loss: 0.5874 - val_acc: 0.7890\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.2746 - acc: 0.9003 - val_loss: 0.5824 - val_acc: 0.7902\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2736 - acc: 0.9008 - val_loss: 0.5766 - val_acc: 0.7878\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 1s 25ms/step - loss: 0.2729 - acc: 0.9012 - val_loss: 0.5750 - val_acc: 0.7843\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.2728 - acc: 0.9013 - val_loss: 0.5726 - val_acc: 0.7843\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2730 - acc: 0.9012 - val_loss: 0.5870 - val_acc: 0.7974\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2734 - acc: 0.9006 - val_loss: 0.5721 - val_acc: 0.7843\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.2734 - acc: 0.8998 - val_loss: 0.5778 - val_acc: 0.7878\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.2715 - acc: 0.9017 - val_loss: 0.5838 - val_acc: 0.7878\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.2711 - acc: 0.9017 - val_loss: 0.5714 - val_acc: 0.7807\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.2709 - acc: 0.9022 - val_loss: 0.5830 - val_acc: 0.7938\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.2711 - acc: 0.9022 - val_loss: 0.5635 - val_acc: 0.7843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:16:40,120]\u001B[0m Trial 0 finished with value: 0.784267008304596 and parameters: {'lstm_first_layer_size': 196, 'learning_rate': 1.2173105362980854e-05}. Best is trial 0 with value: 0.784267008304596.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 300)         2820900   \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 300)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      120100    \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 47)                27824     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 48        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,968,872\n",
      "Trainable params: 147,972\n",
      "Non-trainable params: 2,820,900\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 28ms/step - loss: 0.7606 - acc: 0.5639 - val_loss: 0.6733 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6726 - acc: 0.6054 - val_loss: 0.6679 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6674 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6647 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6661 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6662 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6647 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6647 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6720 - acc: 0.6054 - val_loss: 0.6672 - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6717 - acc: 0.6054 - val_loss: 0.6659 - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6678 - val_acc: 0.6186\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6717 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6663 - val_acc: 0.6186\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6727 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6647 - val_acc: 0.6186\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6661 - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6717 - acc: 0.6054 - val_loss: 0.6675 - val_acc: 0.6186\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6664 - val_acc: 0.6186\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6662 - val_acc: 0.6186\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6659 - val_acc: 0.6186\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6665 - val_acc: 0.6186\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6659 - val_acc: 0.6186\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6663 - val_acc: 0.6186\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6662 - val_acc: 0.6186\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:17:20,618]\u001B[0m Trial 1 finished with value: 0.6185935735702515 and parameters: {'lstm_first_layer_size': 47, 'learning_rate': 0.04331703956826088}. Best is trial 0 with value: 0.784267008304596.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 300)         2820900   \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 300)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      120100    \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 135)               127440    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 136       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,068,576\n",
      "Trainable params: 247,676\n",
      "Non-trainable params: 2,820,900\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 3s 36ms/step - loss: 0.6920 - acc: 0.6059 - val_loss: 0.6903 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6889 - acc: 0.6054 - val_loss: 0.6855 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6828 - acc: 0.6054 - val_loss: 0.6750 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6738 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6640 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6701 - acc: 0.6054 - val_loss: 0.6634 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6693 - acc: 0.6057 - val_loss: 0.6618 - val_acc: 0.6210\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6611 - acc: 0.6078 - val_loss: 0.5893 - val_acc: 0.6603\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5455 - acc: 0.7307 - val_loss: 0.5110 - val_acc: 0.7580\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5036 - acc: 0.7626 - val_loss: 0.4975 - val_acc: 0.7616\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.4742 - acc: 0.7769 - val_loss: 0.4769 - val_acc: 0.7712\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.4530 - acc: 0.7875 - val_loss: 0.4733 - val_acc: 0.7807\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.4387 - acc: 0.7985 - val_loss: 0.4670 - val_acc: 0.7855\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.4287 - acc: 0.8056 - val_loss: 0.4669 - val_acc: 0.7807\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.4172 - acc: 0.8123 - val_loss: 0.4630 - val_acc: 0.7878\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.4065 - acc: 0.8212 - val_loss: 0.4599 - val_acc: 0.7926\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.3972 - acc: 0.8269 - val_loss: 0.4494 - val_acc: 0.7986\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.3882 - acc: 0.8297 - val_loss: 0.4567 - val_acc: 0.7962\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.3755 - acc: 0.8402 - val_loss: 0.4621 - val_acc: 0.7998\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.3665 - acc: 0.8457 - val_loss: 0.4571 - val_acc: 0.8021\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.3534 - acc: 0.8522 - val_loss: 0.4429 - val_acc: 0.8069\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.3395 - acc: 0.8611 - val_loss: 0.4482 - val_acc: 0.8045\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.3282 - acc: 0.8665 - val_loss: 0.4459 - val_acc: 0.8021\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.3187 - acc: 0.8740 - val_loss: 0.4486 - val_acc: 0.8117\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.3236 - acc: 0.8691 - val_loss: 0.4358 - val_acc: 0.8069\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.3139 - acc: 0.8747 - val_loss: 0.4662 - val_acc: 0.8117\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.3188 - acc: 0.8715 - val_loss: 0.4316 - val_acc: 0.8045\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.3063 - acc: 0.8783 - val_loss: 0.4917 - val_acc: 0.8212\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.2905 - acc: 0.8897 - val_loss: 0.4678 - val_acc: 0.8117\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.2786 - acc: 0.8963 - val_loss: 0.4789 - val_acc: 0.8117\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.2702 - acc: 0.9012 - val_loss: 0.5002 - val_acc: 0.8200\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.2687 - acc: 0.9012 - val_loss: 0.5083 - val_acc: 0.8212\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.2623 - acc: 0.9036 - val_loss: 0.5065 - val_acc: 0.8200\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.2551 - acc: 0.9074 - val_loss: 0.5193 - val_acc: 0.8164\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.2708 - acc: 0.8966 - val_loss: 0.5461 - val_acc: 0.8188\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.2637 - acc: 0.9027 - val_loss: 0.5172 - val_acc: 0.8141\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2448 - acc: 0.9144 - val_loss: 0.5172 - val_acc: 0.8141\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2436 - acc: 0.9153 - val_loss: 0.5207 - val_acc: 0.8129\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2374 - acc: 0.9193 - val_loss: 0.5194 - val_acc: 0.8164\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.2342 - acc: 0.9210 - val_loss: 0.5366 - val_acc: 0.8176\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2317 - acc: 0.9219 - val_loss: 0.5227 - val_acc: 0.8105\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2349 - acc: 0.9186 - val_loss: 0.5202 - val_acc: 0.8260\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2361 - acc: 0.9176 - val_loss: 0.5199 - val_acc: 0.8129\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.2450 - acc: 0.9113 - val_loss: 0.4902 - val_acc: 0.8057\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2257 - acc: 0.9240 - val_loss: 0.5893 - val_acc: 0.8141\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2287 - acc: 0.9212 - val_loss: 0.6056 - val_acc: 0.8200\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2335 - acc: 0.9172 - val_loss: 0.5394 - val_acc: 0.8153\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.2202 - acc: 0.9268 - val_loss: 0.5266 - val_acc: 0.8200\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2126 - acc: 0.9301 - val_loss: 0.5474 - val_acc: 0.8284\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.2212 - acc: 0.9244 - val_loss: 0.5265 - val_acc: 0.8212\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.2075 - acc: 0.9329 - val_loss: 0.5167 - val_acc: 0.8176\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.2051 - acc: 0.9334 - val_loss: 0.5872 - val_acc: 0.8176\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.2073 - acc: 0.9320 - val_loss: 0.5499 - val_acc: 0.8296\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.2004 - acc: 0.9359 - val_loss: 0.5435 - val_acc: 0.8200\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.2027 - acc: 0.9346 - val_loss: 0.6005 - val_acc: 0.8224\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.1973 - acc: 0.9378 - val_loss: 0.5559 - val_acc: 0.8212\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.1930 - acc: 0.9395 - val_loss: 0.5755 - val_acc: 0.8188\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.2020 - acc: 0.9341 - val_loss: 0.5265 - val_acc: 0.8200\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.1993 - acc: 0.9366 - val_loss: 0.5804 - val_acc: 0.8188\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.1900 - acc: 0.9414 - val_loss: 0.5653 - val_acc: 0.8236\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.2034 - acc: 0.9339 - val_loss: 0.5457 - val_acc: 0.7962\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.2244 - acc: 0.9228 - val_loss: 0.5114 - val_acc: 0.8260\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.1908 - acc: 0.9414 - val_loss: 0.5682 - val_acc: 0.8248\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.1833 - acc: 0.9447 - val_loss: 0.5553 - val_acc: 0.8212\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.1796 - acc: 0.9454 - val_loss: 0.5908 - val_acc: 0.8284\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.1812 - acc: 0.9456 - val_loss: 0.5987 - val_acc: 0.8236\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.1769 - acc: 0.9475 - val_loss: 0.5661 - val_acc: 0.8224\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.1815 - acc: 0.9454 - val_loss: 0.6198 - val_acc: 0.8188\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.1863 - acc: 0.9427 - val_loss: 0.5453 - val_acc: 0.8260\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.2009 - acc: 0.9343 - val_loss: 0.5325 - val_acc: 0.8272\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.2016 - acc: 0.9324 - val_loss: 0.6035 - val_acc: 0.8129\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.1868 - acc: 0.9428 - val_loss: 0.5434 - val_acc: 0.8272\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.1742 - acc: 0.9481 - val_loss: 0.5525 - val_acc: 0.8200\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.1855 - acc: 0.9420 - val_loss: 0.6519 - val_acc: 0.8260\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.1844 - acc: 0.9428 - val_loss: 0.5433 - val_acc: 0.8093\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.1950 - acc: 0.9379 - val_loss: 0.6491 - val_acc: 0.8224\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 1s 24ms/step - loss: 0.1790 - acc: 0.9458 - val_loss: 0.5787 - val_acc: 0.8236\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.1684 - acc: 0.9508 - val_loss: 0.5767 - val_acc: 0.8224\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.1647 - acc: 0.9524 - val_loss: 0.6175 - val_acc: 0.8284\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.1656 - acc: 0.9512 - val_loss: 0.6864 - val_acc: 0.8153\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.1639 - acc: 0.9521 - val_loss: 0.5946 - val_acc: 0.8272\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.1631 - acc: 0.9529 - val_loss: 0.6592 - val_acc: 0.8188\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.1685 - acc: 0.9507 - val_loss: 0.6119 - val_acc: 0.8248\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.1624 - acc: 0.9529 - val_loss: 0.5722 - val_acc: 0.8153\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.1607 - acc: 0.9543 - val_loss: 0.5740 - val_acc: 0.8260\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.1602 - acc: 0.9536 - val_loss: 0.5874 - val_acc: 0.8272\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.1605 - acc: 0.9545 - val_loss: 0.6672 - val_acc: 0.8188\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.1583 - acc: 0.9552 - val_loss: 0.5938 - val_acc: 0.8176\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.1656 - acc: 0.9501 - val_loss: 0.6612 - val_acc: 0.8284\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.1719 - acc: 0.9474 - val_loss: 0.5798 - val_acc: 0.8200\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.1567 - acc: 0.9559 - val_loss: 0.6156 - val_acc: 0.8224\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.1531 - acc: 0.9575 - val_loss: 0.6185 - val_acc: 0.8200\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.1540 - acc: 0.9573 - val_loss: 0.6028 - val_acc: 0.8236\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.1570 - acc: 0.9549 - val_loss: 0.6128 - val_acc: 0.8176\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.1745 - acc: 0.9465 - val_loss: 0.6455 - val_acc: 0.8248\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.1673 - acc: 0.9510 - val_loss: 0.5725 - val_acc: 0.8284\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.1556 - acc: 0.9564 - val_loss: 0.5826 - val_acc: 0.8200\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 1s 23ms/step - loss: 0.1540 - acc: 0.9573 - val_loss: 0.5897 - val_acc: 0.8260\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.1511 - acc: 0.9578 - val_loss: 0.6450 - val_acc: 0.8272\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.1510 - acc: 0.9583 - val_loss: 0.5873 - val_acc: 0.8260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:18:09,928]\u001B[0m Trial 2 finished with value: 0.8259832859039307 and parameters: {'lstm_first_layer_size': 135, 'learning_rate': 4.879004187370446e-05}. Best is trial 2 with value: 0.8259832859039307.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 300)         2820900   \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 300)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      120100    \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 18)                8568      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 19        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,949,587\n",
      "Trainable params: 128,687\n",
      "Non-trainable params: 2,820,900\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 30ms/step - loss: 0.6884 - acc: 0.6054 - val_loss: 0.6785 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6745 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6707 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6705 - acc: 0.6054 - val_loss: 0.6640 - val_acc: 0.6186\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6611 - acc: 0.6216 - val_loss: 0.5997 - val_acc: 0.7354\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6501 - acc: 0.6460 - val_loss: 0.6652 - val_acc: 0.6472\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6650 - acc: 0.6331 - val_loss: 0.6577 - val_acc: 0.6341\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6588 - acc: 0.6326 - val_loss: 0.6552 - val_acc: 0.6377\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6541 - acc: 0.6378 - val_loss: 0.6487 - val_acc: 0.6472\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6518 - acc: 0.6394 - val_loss: 0.6463 - val_acc: 0.6496\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6503 - acc: 0.6402 - val_loss: 0.6482 - val_acc: 0.6472\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6468 - acc: 0.6484 - val_loss: 0.6806 - val_acc: 0.6579\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.7052 - acc: 0.5967 - val_loss: 0.6481 - val_acc: 0.6198\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6412 - acc: 0.6364 - val_loss: 0.6385 - val_acc: 0.6257\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6314 - acc: 0.6456 - val_loss: 0.6361 - val_acc: 0.6222\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6299 - acc: 0.6401 - val_loss: 0.6357 - val_acc: 0.6210\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6296 - acc: 0.6401 - val_loss: 0.6356 - val_acc: 0.6210\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6293 - acc: 0.6402 - val_loss: 0.6345 - val_acc: 0.6222\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6293 - acc: 0.6401 - val_loss: 0.6353 - val_acc: 0.6210\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6294 - acc: 0.6401 - val_loss: 0.6353 - val_acc: 0.6210\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6295 - acc: 0.6401 - val_loss: 0.6348 - val_acc: 0.6210\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6291 - acc: 0.6404 - val_loss: 0.6349 - val_acc: 0.6222\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6285 - acc: 0.6418 - val_loss: 0.6357 - val_acc: 0.6222\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6285 - acc: 0.6428 - val_loss: 0.6371 - val_acc: 0.6246\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6302 - acc: 0.6469 - val_loss: 0.6367 - val_acc: 0.6305\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6320 - acc: 0.6456 - val_loss: 0.6365 - val_acc: 0.6305\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6319 - acc: 0.6456 - val_loss: 0.6364 - val_acc: 0.6305\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6319 - acc: 0.6456 - val_loss: 0.6364 - val_acc: 0.6305\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6318 - acc: 0.6456 - val_loss: 0.6365 - val_acc: 0.6305\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6318 - acc: 0.6458 - val_loss: 0.6363 - val_acc: 0.6305\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6317 - acc: 0.6460 - val_loss: 0.6364 - val_acc: 0.6305\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6318 - acc: 0.6456 - val_loss: 0.6362 - val_acc: 0.6305\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6316 - acc: 0.6460 - val_loss: 0.6366 - val_acc: 0.6305\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6317 - acc: 0.6460 - val_loss: 0.6365 - val_acc: 0.6305\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6317 - acc: 0.6460 - val_loss: 0.6364 - val_acc: 0.6305\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6317 - acc: 0.6460 - val_loss: 0.6362 - val_acc: 0.6305\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6319 - acc: 0.6456 - val_loss: 0.6365 - val_acc: 0.6305\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6317 - acc: 0.6458 - val_loss: 0.6362 - val_acc: 0.6305\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6318 - acc: 0.6458 - val_loss: 0.6365 - val_acc: 0.6305\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6319 - acc: 0.6458 - val_loss: 0.6367 - val_acc: 0.6305\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6315 - acc: 0.6458 - val_loss: 0.6361 - val_acc: 0.6281\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6286 - acc: 0.6449 - val_loss: 0.6366 - val_acc: 0.6222\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6296 - acc: 0.6409 - val_loss: 0.6364 - val_acc: 0.6210\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6292 - acc: 0.6413 - val_loss: 0.6366 - val_acc: 0.6210\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 13ms/step - loss: 0.6289 - acc: 0.6416 - val_loss: 0.6365 - val_acc: 0.6210\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6290 - acc: 0.6415 - val_loss: 0.6380 - val_acc: 0.6186\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6293 - acc: 0.6406 - val_loss: 0.6373 - val_acc: 0.6186\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6293 - acc: 0.6406 - val_loss: 0.6374 - val_acc: 0.6186\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6293 - acc: 0.6404 - val_loss: 0.6393 - val_acc: 0.6150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:18:47,964]\u001B[0m Trial 3 finished with value: 0.6150178909301758 and parameters: {'lstm_first_layer_size': 18, 'learning_rate': 0.0004912565701675664}. Best is trial 2 with value: 0.8259832859039307.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 300)         2820900   \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 300)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      120100    \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 126)               114408    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 127       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,055,535\n",
      "Trainable params: 234,635\n",
      "Non-trainable params: 2,820,900\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 37ms/step - loss: 0.6796 - acc: 0.6055 - val_loss: 0.6686 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6719 - acc: 0.6054 - val_loss: 0.6668 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6664 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6647 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6678 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6718 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6662 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6973 - acc: 0.5933 - val_loss: 0.6663 - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:19:36,127]\u001B[0m Trial 4 finished with value: 0.6185935735702515 and parameters: {'lstm_first_layer_size': 126, 'learning_rate': 0.0011056513684751764}. Best is trial 2 with value: 0.8259832859039307.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  5\n",
      "  Number of pruned trials:  0\n",
      "  Number of complete trials:  5\n",
      "Best trial:\n",
      "  Value:  0.8259832859039307\n",
      "lemmas nkjp+wiki-lemmas-all-300-cbow-hs.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:19:36,635]\u001B[0m A new study created in RDB with name: no-name-ac36bacb-4760-47c8-9630-3812a8c8edbe\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9058, 300)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 300)         2717400   \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 300)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      120100    \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 71)                48848     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 72        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,886,420\n",
      "Trainable params: 169,020\n",
      "Non-trainable params: 2,717,400\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 34ms/step - loss: 0.6929 - acc: 0.6054 - val_loss: 0.6926 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6924 - acc: 0.6054 - val_loss: 0.6920 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6918 - acc: 0.6054 - val_loss: 0.6913 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6912 - acc: 0.6054 - val_loss: 0.6904 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6904 - acc: 0.6054 - val_loss: 0.6895 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6895 - acc: 0.6054 - val_loss: 0.6885 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6885 - acc: 0.6054 - val_loss: 0.6872 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6874 - acc: 0.6054 - val_loss: 0.6858 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6860 - acc: 0.6054 - val_loss: 0.6841 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6844 - acc: 0.6054 - val_loss: 0.6823 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6827 - acc: 0.6054 - val_loss: 0.6799 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6806 - acc: 0.6054 - val_loss: 0.6772 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6782 - acc: 0.6054 - val_loss: 0.6742 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6756 - acc: 0.6054 - val_loss: 0.6708 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6730 - acc: 0.6054 - val_loss: 0.6674 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6706 - acc: 0.6054 - val_loss: 0.6647 - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6703 - acc: 0.6054 - val_loss: 0.6644 - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6703 - acc: 0.6054 - val_loss: 0.6642 - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6702 - acc: 0.6054 - val_loss: 0.6641 - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6701 - acc: 0.6054 - val_loss: 0.6640 - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6700 - acc: 0.6054 - val_loss: 0.6641 - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6697 - acc: 0.6054 - val_loss: 0.6635 - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6693 - acc: 0.6054 - val_loss: 0.6632 - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6683 - acc: 0.6054 - val_loss: 0.6610 - val_acc: 0.6186\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6626 - acc: 0.6054 - val_loss: 0.6450 - val_acc: 0.6186\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6343 - acc: 0.6054 - val_loss: 0.6041 - val_acc: 0.6186\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.5848 - acc: 0.6055 - val_loss: 0.5724 - val_acc: 0.6210\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.5520 - acc: 0.6062 - val_loss: 0.5599 - val_acc: 0.6222\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.5327 - acc: 0.6071 - val_loss: 0.5479 - val_acc: 0.6246\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.5189 - acc: 0.6087 - val_loss: 0.5368 - val_acc: 0.6138\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.5069 - acc: 0.6573 - val_loss: 0.5295 - val_acc: 0.7437\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.4973 - acc: 0.7673 - val_loss: 0.5408 - val_acc: 0.7437\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.4895 - acc: 0.7591 - val_loss: 0.5404 - val_acc: 0.7378\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.4831 - acc: 0.7575 - val_loss: 0.5307 - val_acc: 0.7187\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.4807 - acc: 0.7542 - val_loss: 0.5215 - val_acc: 0.7056\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4791 - acc: 0.7572 - val_loss: 0.5404 - val_acc: 0.7282\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.4755 - acc: 0.7617 - val_loss: 0.5333 - val_acc: 0.7390\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4714 - acc: 0.7668 - val_loss: 0.5322 - val_acc: 0.7294\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.4667 - acc: 0.7683 - val_loss: 0.5302 - val_acc: 0.7318\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4653 - acc: 0.7697 - val_loss: 0.5270 - val_acc: 0.7402\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4679 - acc: 0.7615 - val_loss: 0.5305 - val_acc: 0.7402\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4614 - acc: 0.7717 - val_loss: 0.5232 - val_acc: 0.7330\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.4566 - acc: 0.7767 - val_loss: 0.5230 - val_acc: 0.7354\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4539 - acc: 0.7781 - val_loss: 0.5296 - val_acc: 0.7402\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4533 - acc: 0.7800 - val_loss: 0.5296 - val_acc: 0.7390\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4526 - acc: 0.7797 - val_loss: 0.5314 - val_acc: 0.7342\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.4502 - acc: 0.7800 - val_loss: 0.5282 - val_acc: 0.7378\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4478 - acc: 0.7819 - val_loss: 0.5282 - val_acc: 0.7259\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4552 - acc: 0.7769 - val_loss: 0.5266 - val_acc: 0.7271\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4499 - acc: 0.7771 - val_loss: 0.5196 - val_acc: 0.7426\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4444 - acc: 0.7835 - val_loss: 0.5203 - val_acc: 0.7426\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.4433 - acc: 0.7847 - val_loss: 0.5202 - val_acc: 0.7449\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4430 - acc: 0.7854 - val_loss: 0.5195 - val_acc: 0.7426\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4416 - acc: 0.7868 - val_loss: 0.5226 - val_acc: 0.7402\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4432 - acc: 0.7856 - val_loss: 0.5204 - val_acc: 0.7449\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4399 - acc: 0.7875 - val_loss: 0.5267 - val_acc: 0.7437\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4396 - acc: 0.7889 - val_loss: 0.5204 - val_acc: 0.7485\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4396 - acc: 0.7882 - val_loss: 0.5205 - val_acc: 0.7461\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4393 - acc: 0.7901 - val_loss: 0.5157 - val_acc: 0.7509\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4355 - acc: 0.7914 - val_loss: 0.5175 - val_acc: 0.7521\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4361 - acc: 0.7912 - val_loss: 0.5192 - val_acc: 0.7473\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4348 - acc: 0.7926 - val_loss: 0.5161 - val_acc: 0.7545\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4349 - acc: 0.7922 - val_loss: 0.5199 - val_acc: 0.7437\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4342 - acc: 0.7927 - val_loss: 0.5156 - val_acc: 0.7557\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4337 - acc: 0.7940 - val_loss: 0.5161 - val_acc: 0.7569\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4319 - acc: 0.7948 - val_loss: 0.5168 - val_acc: 0.7521\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4309 - acc: 0.7957 - val_loss: 0.5224 - val_acc: 0.7557\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4310 - acc: 0.7959 - val_loss: 0.5175 - val_acc: 0.7592\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4369 - acc: 0.7907 - val_loss: 0.5217 - val_acc: 0.7473\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4356 - acc: 0.7929 - val_loss: 0.5192 - val_acc: 0.7461\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4320 - acc: 0.7938 - val_loss: 0.5172 - val_acc: 0.7461\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4322 - acc: 0.7947 - val_loss: 0.5156 - val_acc: 0.7569\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4329 - acc: 0.7938 - val_loss: 0.5181 - val_acc: 0.7592\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4298 - acc: 0.7966 - val_loss: 0.5115 - val_acc: 0.7580\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4297 - acc: 0.7966 - val_loss: 0.5090 - val_acc: 0.7557\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4323 - acc: 0.7964 - val_loss: 0.5118 - val_acc: 0.7545\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4297 - acc: 0.7969 - val_loss: 0.5141 - val_acc: 0.7604\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4281 - acc: 0.7982 - val_loss: 0.5069 - val_acc: 0.7616\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4274 - acc: 0.7988 - val_loss: 0.5103 - val_acc: 0.7592\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4275 - acc: 0.7985 - val_loss: 0.5119 - val_acc: 0.7616\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4276 - acc: 0.7983 - val_loss: 0.5106 - val_acc: 0.7604\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4262 - acc: 0.7995 - val_loss: 0.5136 - val_acc: 0.7604\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4259 - acc: 0.8001 - val_loss: 0.5154 - val_acc: 0.7592\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4277 - acc: 0.7987 - val_loss: 0.5154 - val_acc: 0.7580\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4277 - acc: 0.7995 - val_loss: 0.5240 - val_acc: 0.7604\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4331 - acc: 0.7947 - val_loss: 0.5138 - val_acc: 0.7569\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4296 - acc: 0.7990 - val_loss: 0.5102 - val_acc: 0.7604\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4253 - acc: 0.8006 - val_loss: 0.5111 - val_acc: 0.7604\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4250 - acc: 0.8008 - val_loss: 0.5107 - val_acc: 0.7616\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.4271 - acc: 0.7985 - val_loss: 0.5088 - val_acc: 0.7592\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4248 - acc: 0.8008 - val_loss: 0.5104 - val_acc: 0.7580\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4245 - acc: 0.8011 - val_loss: 0.5267 - val_acc: 0.7580\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4261 - acc: 0.8001 - val_loss: 0.5089 - val_acc: 0.7557\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.4255 - acc: 0.8002 - val_loss: 0.5307 - val_acc: 0.7580\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4240 - acc: 0.8013 - val_loss: 0.5072 - val_acc: 0.7545\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4245 - acc: 0.8008 - val_loss: 0.5234 - val_acc: 0.7592\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.4241 - acc: 0.8015 - val_loss: 0.5144 - val_acc: 0.7592\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.4237 - acc: 0.8018 - val_loss: 0.5301 - val_acc: 0.7592\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.4242 - acc: 0.8015 - val_loss: 0.5107 - val_acc: 0.7580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:20:18,887]\u001B[0m Trial 0 finished with value: 0.7580453157424927 and parameters: {'lstm_first_layer_size': 71, 'learning_rate': 1.4092641648206498e-05}. Best is trial 0 with value: 0.7580453157424927.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 300)         2717400   \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 300)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      120100    \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 119)               104720    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 120       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,942,340\n",
      "Trainable params: 224,940\n",
      "Non-trainable params: 2,717,400\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 34ms/step - loss: 0.6735 - acc: 0.6026 - val_loss: 0.6661 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6666 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6677 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6717 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6661 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6674 - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6670 - val_acc: 0.6186\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6667 - val_acc: 0.6186\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6666 - val_acc: 0.6186\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6647 - val_acc: 0.6186\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6647 - val_acc: 0.6186\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6662 - val_acc: 0.6186\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6647 - val_acc: 0.6186\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6666 - val_acc: 0.6186\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6661 - val_acc: 0.6186\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6659 - val_acc: 0.6186\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6662 - val_acc: 0.6186\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6647 - val_acc: 0.6186\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6673 - val_acc: 0.6186\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6659 - val_acc: 0.6186\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6726 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6722 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6667 - val_acc: 0.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:21:05,426]\u001B[0m Trial 1 finished with value: 0.6185935735702515 and parameters: {'lstm_first_layer_size': 119, 'learning_rate': 0.048537797279404306}. Best is trial 0 with value: 0.7580453157424927.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 300)         2717400   \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 300)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      120100    \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                42240     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,879,805\n",
      "Trainable params: 162,405\n",
      "Non-trainable params: 2,717,400\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 30ms/step - loss: 0.6766 - acc: 0.6054 - val_loss: 0.6673 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6659 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6647 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6707 - acc: 0.6054 - val_loss: 0.6666 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6647 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6726 - acc: 0.5963 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6667 - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6714 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6717 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:21:48,531]\u001B[0m Trial 2 finished with value: 0.6185935735702515 and parameters: {'lstm_first_layer_size': 64, 'learning_rate': 0.0017315489030366885}. Best is trial 0 with value: 0.7580453157424927.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 300)         2717400   \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 300)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      120100    \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 94)                73320     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 95        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,910,915\n",
      "Trainable params: 193,515\n",
      "Non-trainable params: 2,717,400\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 32ms/step - loss: 0.6747 - acc: 0.6048 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6671 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6722 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6713 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6658 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6666 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6717 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6715 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6660 - val_acc: 0.6186\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6719 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6659 - val_acc: 0.6186\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6659 - val_acc: 0.6186\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6648 - val_acc: 0.6186\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6657 - val_acc: 0.6186\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6656 - val_acc: 0.6186\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6711 - acc: 0.6054 - val_loss: 0.6655 - val_acc: 0.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-04-12 16:22:31,163]\u001B[0m Trial 3 finished with value: 0.6185935735702515 and parameters: {'lstm_first_layer_size': 94, 'learning_rate': 0.004713217800036326}. Best is trial 0 with value: 0.7580453157424927.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 300)         2717400   \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 1, None, 300)      0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 1, None, 100)      120100    \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 1, None, 100)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, None)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 183)               207888    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 184       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,045,572\n",
      "Trainable params: 328,172\n",
      "Non-trainable params: 2,717,400\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 4s 38ms/step - loss: 0.6801 - acc: 0.6054 - val_loss: 0.6685 - val_acc: 0.6186\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6717 - acc: 0.6054 - val_loss: 0.6674 - val_acc: 0.6186\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6712 - acc: 0.6054 - val_loss: 0.6647 - val_acc: 0.6186\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6678 - val_acc: 0.6186\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6719 - acc: 0.6054 - val_loss: 0.6666 - val_acc: 0.6186\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 17ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6651 - val_acc: 0.6186\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6716 - acc: 0.6054 - val_loss: 0.6666 - val_acc: 0.6186\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6806 - acc: 0.5993 - val_loss: 0.6671 - val_acc: 0.6186\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6717 - acc: 0.6054 - val_loss: 0.6659 - val_acc: 0.6186\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6710 - acc: 0.6054 - val_loss: 0.6649 - val_acc: 0.6186\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6653 - val_acc: 0.6186\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6654 - val_acc: 0.6186\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6650 - val_acc: 0.6186\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.6708 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 18ms/step - loss: 0.6709 - acc: 0.6054 - val_loss: 0.6652 - val_acc: 0.6186\n",
      "Epoch 16/100\n",
      "20/23 [=========================>....] - ETA: 0s - loss: 0.6715 - acc: 0.6039"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[33m[W 2023-04-12 16:22:41,967]\u001B[0m Trial 4 failed with parameters: {'lstm_first_layer_size': 183, 'learning_rate': 0.00060382567176119} because of the following error: KeyboardInterrupt().\u001B[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"<ipython-input-91-a88a7a8aabf6>\", line 21, in <lambda>\n",
      "    func = lambda trail: objective(trail, which, embedding_layer, x_train, y_train, x_valid, y_valid)\n",
      "  File \"<ipython-input-28-561794553c96>\", line 8, in objective\n",
      "    model.fit(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1694, in fit\n",
      "    val_logs = self.evaluate(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 2040, in evaluate\n",
      "    tmp_logs = self.test_function(iterator)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 880, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 919, in _call\n",
      "    results = self._variable_creation_fn(*args, **kwds)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\", line 134, in __call__\n",
      "    return concrete_function._call_flat(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 1745, in _call_flat\n",
      "    return self._build_call_outputs(self._inference_function.call(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\", line 378, in call\n",
      "    outputs = execute.execute(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\", line 52, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n",
      "\u001B[33m[W 2023-04-12 16:22:41,968]\u001B[0m Trial 4 failed with value None.\u001B[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [110], line 23\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlemmas\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m data \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mforms\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m file_name:\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;28mprint\u001B[39m(data, file_name)\n\u001B[0;32m---> 23\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwhich\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbin_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodelss\u001B[49m\u001B[43m[\u001B[49m\u001B[43mfile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;241m!=\u001B[39m {}:\n\u001B[1;32m     25\u001B[0m     dest_folder_path \u001B[38;5;241m=\u001B[39m Path(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./results/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mwhich\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn [91], line 27\u001B[0m, in \u001B[0;36mmain\u001B[0;34m(which, x, y, word2vec_model, n_trails)\u001B[0m\n\u001B[1;32m     21\u001B[0m func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m trail: objective(trail, which, embedding_layer, x_train, y_train, x_valid, y_valid)\n\u001B[1;32m     22\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(\n\u001B[1;32m     23\u001B[0m     direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     24\u001B[0m     pruner\u001B[38;5;241m=\u001B[39moptuna\u001B[38;5;241m.\u001B[39mpruners\u001B[38;5;241m.\u001B[39mMedianPruner(),\n\u001B[1;32m     25\u001B[0m     storage\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msqlite:///db.sqlite3\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     26\u001B[0m )\n\u001B[0;32m---> 27\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trails\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m pruned_trials \u001B[38;5;241m=\u001B[39m study\u001B[38;5;241m.\u001B[39mget_trials(deepcopy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, states\u001B[38;5;241m=\u001B[39m[TrialState\u001B[38;5;241m.\u001B[39mPRUNED])\n\u001B[1;32m     30\u001B[0m complete_trials \u001B[38;5;241m=\u001B[39m study\u001B[38;5;241m.\u001B[39mget_trials(deepcopy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, states\u001B[38;5;241m=\u001B[39m[TrialState\u001B[38;5;241m.\u001B[39mCOMPLETE])\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/study.py:425\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[1;32m    321\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimize\u001B[39m(\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    323\u001B[0m     func: ObjectiveFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    330\u001B[0m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    331\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    332\u001B[0m     \u001B[38;5;124;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[1;32m    333\u001B[0m \n\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;124;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 425\u001B[0m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    426\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    427\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    428\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    429\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    430\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    431\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    432\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    433\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    434\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    435\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:66\u001B[0m, in \u001B[0;36m_optimize\u001B[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m---> 66\u001B[0m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     76\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     78\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     79\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:163\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[1;32m    160\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 163\u001B[0m     frozen_trial \u001B[38;5;241m=\u001B[39m \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    165\u001B[0m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[1;32m    167\u001B[0m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[1;32m    168\u001B[0m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[1;32m    169\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:251\u001B[0m, in \u001B[0;36m_run_trial\u001B[0;34m(study, func, catch)\u001B[0m\n\u001B[1;32m    244\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    247\u001B[0m     frozen_trial\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL\n\u001B[1;32m    248\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    249\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[1;32m    250\u001B[0m ):\n\u001B[0;32m--> 251\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/optuna/study/_optimize.py:200\u001B[0m, in \u001B[0;36m_run_trial\u001B[0;34m(study, func, catch)\u001B[0m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial\u001B[38;5;241m.\u001B[39m_trial_id, study\u001B[38;5;241m.\u001B[39m_storage):\n\u001B[1;32m    199\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 200\u001B[0m         value_or_values \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    202\u001B[0m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[1;32m    203\u001B[0m         state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "Cell \u001B[0;32mIn [91], line 21\u001B[0m, in \u001B[0;36mmain.<locals>.<lambda>\u001B[0;34m(trail)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m#create model\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m#test train split\u001B[39;00m\n\u001B[1;32m     19\u001B[0m x_train, x_valid, y_train, y_valid, x_test, y_test  \u001B[38;5;241m=\u001B[39m split_dataset(vectorized_x, y)\n\u001B[0;32m---> 21\u001B[0m func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m trail: \u001B[43mobjective\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrail\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhich\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_layer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_valid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_valid\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(\n\u001B[1;32m     23\u001B[0m     direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     24\u001B[0m     pruner\u001B[38;5;241m=\u001B[39moptuna\u001B[38;5;241m.\u001B[39mpruners\u001B[38;5;241m.\u001B[39mMedianPruner(),\n\u001B[1;32m     25\u001B[0m     storage\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msqlite:///db.sqlite3\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     26\u001B[0m )\n\u001B[1;32m     27\u001B[0m study\u001B[38;5;241m.\u001B[39moptimize(func, n_trials\u001B[38;5;241m=\u001B[39mn_trails)\n",
      "Cell \u001B[0;32mIn [28], line 8\u001B[0m, in \u001B[0;36mobjective\u001B[0;34m(trial, which, embedding_layer, x_train, y_train, x_valid, y_valid)\u001B[0m\n\u001B[1;32m      5\u001B[0m model \u001B[38;5;241m=\u001B[39m create_model(which, embedding_layer, trial)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Fit the model on the training data.\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# The KerasPruningCallback checks for pruning condition every epoch.\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mTFKerasPruningCallback\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mval_acc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mEPOCHS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx_valid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_valid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Evaluate the model accuracy on the validation set.\u001B[39;00m\n\u001B[1;32m     19\u001B[0m score \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mevaluate(x_valid, y_valid, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1694\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1679\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_eval_data_handler\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1680\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eval_data_handler \u001B[38;5;241m=\u001B[39m data_adapter\u001B[38;5;241m.\u001B[39mget_data_handler(\n\u001B[1;32m   1681\u001B[0m         x\u001B[38;5;241m=\u001B[39mval_x,\n\u001B[1;32m   1682\u001B[0m         y\u001B[38;5;241m=\u001B[39mval_y,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1692\u001B[0m         steps_per_execution\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution,\n\u001B[1;32m   1693\u001B[0m     )\n\u001B[0;32m-> 1694\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1695\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1696\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1697\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1698\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1699\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1700\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1701\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1702\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1703\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1704\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1705\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_use_cached_eval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1706\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1707\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m   1708\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name: val \u001B[38;5;28;01mfor\u001B[39;00m name, val \u001B[38;5;129;01min\u001B[39;00m val_logs\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m   1709\u001B[0m }\n\u001B[1;32m   1710\u001B[0m epoch_logs\u001B[38;5;241m.\u001B[39mupdate(val_logs)\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:2040\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[1;32m   2036\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   2037\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m, step_num\u001B[38;5;241m=\u001B[39mstep, _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   2038\u001B[0m ):\n\u001B[1;32m   2039\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_test_batch_begin(step)\n\u001B[0;32m-> 2040\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2041\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   2042\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    877\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    879\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 880\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    882\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    883\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:919\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    916\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    917\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[1;32m    918\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[0;32m--> 919\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    920\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001B[1;32m    921\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    922\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    132\u001B[0m   (concrete_function,\n\u001B[1;32m    133\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m--> 134\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1741\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1743\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1744\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1745\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1746\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1747\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1748\u001B[0m     args,\n\u001B[1;32m   1749\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1750\u001B[0m     executing_eagerly)\n\u001B[1;32m   1751\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    376\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    377\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 378\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    379\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    380\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    381\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    382\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    383\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    384\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    385\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    386\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    387\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    390\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    391\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for file_name in models.keys():\n",
    "    result = {}\n",
    "    file = models[file_name]\n",
    "\n",
    "    if file_name in curr_results.keys():\n",
    "        continue\n",
    "    if file.name not in modelss.keys():\n",
    "        if str(file).endswith(\".txt\"):\n",
    "            print(file.name)\n",
    "            modelss[file.name] = KeyedVectors.load_word2vec_format(file, binary=False)\n",
    "        elif str(file_name).endswith(\".bin\"):\n",
    "            print(file.name)\n",
    "            modelss[file.name] = KeyedVectors.load(str(file))\n",
    "\n",
    "    for data in dataset.columns:\n",
    "        if data == \"no_stopwords\":\n",
    "            continue\n",
    "        if \"lemmas\" not in data and \"lemmas\" not in file_name:\n",
    "            print(data, file_name)\n",
    "            result =  main(which, dataset[data], bin_y, modelss[file.name])\n",
    "        elif \"lemmas\" in data and \"forms\" not in file_name:\n",
    "            print(data, file_name)\n",
    "            result = main(which, dataset[data], bin_y, modelss[file.name])\n",
    "        if result != {}:\n",
    "            dest_folder_path = Path(f\"./results/{which}/{file_name}/\")\n",
    "            dest_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "            dest_path = dest_folder_path / (data + \".pkl\")\n",
    "            with dest_path.open('wb') as dest_file:\n",
    "                joblib.dump(result, dest_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "res = {}\n",
    "res_path = Path(\"./results\")\n",
    "for _dir in res_path.iterdir():\n",
    "    res[_dir.name] = {}\n",
    "    for file in _dir.iterdir():\n",
    "        one_res = joblib.load(file)\n",
    "        res[_dir.name][file.name] = max(one_res.best_trial.intermediate_values.values())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [
    {
     "data": {
      "text/plain": "lemmas+no_stopwords.pkl          0.865316\nclean+lemmas+no_stopwords.pkl    0.872467\nclean+no_stopwords.pkl           0.871275\nno_stopwords.pkl                 0.872467\nclean.pkl                        0.874851\nlemmas.pkl                       0.868892\nclean+lemmas.pkl                 0.874851\ndtype: float64"
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(res)\n",
    "df.max(axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
